{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "authorship_tag": "ABX9TyN7rLkle1B3AIrLQqbgs1RZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nikalitt1/Clementine-Agriculture/blob/main/Population_based_NN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3BGo8bM0pLWj",
        "outputId": "e23d5057-d90a-4b53-cdce-5b57323c2237"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸŒ± Generation 1 | Population size: 10000\n",
            "  - Training model 1/10000\n",
            "  - Training model 2/10000\n",
            "  - Training model 3/10000\n",
            "  - Training model 4/10000\n",
            "  - Training model 5/10000\n",
            "  - Training model 6/10000\n",
            "  - Training model 7/10000\n",
            "  - Training model 8/10000\n",
            "  - Training model 9/10000\n",
            "  - Training model 10/10000\n",
            "  - Training model 11/10000\n",
            "  - Training model 12/10000\n",
            "  - Training model 13/10000\n",
            "  - Training model 14/10000\n",
            "  - Training model 15/10000\n",
            "  - Training model 16/10000\n",
            "  - Training model 17/10000\n",
            "  - Training model 18/10000\n",
            "  - Training model 19/10000\n",
            "  - Training model 20/10000\n",
            "  - Training model 21/10000\n",
            "  - Training model 22/10000\n",
            "  - Training model 23/10000\n",
            "  - Training model 24/10000\n",
            "  - Training model 25/10000\n",
            "  - Training model 26/10000\n",
            "  - Training model 27/10000\n",
            "  - Training model 28/10000\n",
            "  - Training model 29/10000\n",
            "  - Training model 30/10000\n",
            "  - Training model 31/10000\n",
            "  - Training model 32/10000\n",
            "  - Training model 33/10000\n",
            "  - Training model 34/10000\n",
            "  - Training model 35/10000\n",
            "  - Training model 36/10000\n",
            "  - Training model 37/10000\n",
            "  - Training model 38/10000\n",
            "  - Training model 39/10000\n",
            "  - Training model 40/10000\n",
            "  - Training model 41/10000\n",
            "  - Training model 42/10000\n",
            "  - Training model 43/10000\n",
            "  - Training model 44/10000\n",
            "  - Training model 45/10000\n",
            "  - Training model 46/10000\n",
            "  - Training model 47/10000\n",
            "  - Training model 48/10000\n",
            "  - Training model 49/10000\n",
            "  - Training model 50/10000\n",
            "  - Training model 51/10000\n",
            "  - Training model 52/10000\n",
            "  - Training model 53/10000\n",
            "  - Training model 54/10000\n",
            "  - Training model 55/10000\n",
            "  - Training model 56/10000\n",
            "  - Training model 57/10000\n",
            "  - Training model 58/10000\n",
            "  - Training model 59/10000\n",
            "  - Training model 60/10000\n",
            "  - Training model 61/10000\n",
            "  - Training model 62/10000\n",
            "  - Training model 63/10000\n",
            "  - Training model 64/10000\n",
            "  - Training model 65/10000\n",
            "  - Training model 66/10000\n",
            "  - Training model 67/10000\n",
            "  - Training model 68/10000\n",
            "  - Training model 69/10000\n",
            "  - Training model 70/10000\n",
            "  - Training model 71/10000\n",
            "  - Training model 72/10000\n",
            "  - Training model 73/10000\n",
            "  - Training model 74/10000\n",
            "  - Training model 75/10000\n",
            "  - Training model 76/10000\n",
            "  - Training model 77/10000\n",
            "  - Training model 78/10000\n",
            "  - Training model 79/10000\n",
            "  - Training model 80/10000\n",
            "  - Training model 81/10000\n",
            "  - Training model 82/10000\n",
            "  - Training model 83/10000\n",
            "  - Training model 84/10000\n",
            "  - Training model 85/10000\n",
            "  - Training model 86/10000\n",
            "  - Training model 87/10000\n",
            "  - Training model 88/10000\n",
            "  - Training model 89/10000\n",
            "  - Training model 90/10000\n",
            "  - Training model 91/10000\n",
            "  - Training model 92/10000\n",
            "  - Training model 93/10000\n",
            "  - Training model 94/10000\n",
            "  - Training model 95/10000\n",
            "  - Training model 96/10000\n",
            "  - Training model 97/10000\n",
            "  - Training model 98/10000\n",
            "  - Training model 99/10000\n",
            "  - Training model 100/10000\n",
            "  - Training model 101/10000\n",
            "  - Training model 102/10000\n",
            "  - Training model 103/10000\n",
            "  - Training model 104/10000\n",
            "  - Training model 105/10000\n",
            "  - Training model 106/10000\n",
            "  - Training model 107/10000\n",
            "  - Training model 108/10000\n",
            "  - Training model 109/10000\n",
            "  - Training model 110/10000\n",
            "  - Training model 111/10000\n",
            "  - Training model 112/10000\n",
            "  - Training model 113/10000\n",
            "  - Training model 114/10000\n",
            "  - Training model 115/10000\n",
            "  - Training model 116/10000\n",
            "  - Training model 117/10000\n",
            "  - Training model 118/10000\n",
            "  - Training model 119/10000\n",
            "  - Training model 120/10000\n",
            "  - Training model 121/10000\n",
            "  - Training model 122/10000\n",
            "  - Training model 123/10000\n",
            "  - Training model 124/10000\n",
            "  - Training model 125/10000\n",
            "  - Training model 126/10000\n",
            "  - Training model 127/10000\n",
            "  - Training model 128/10000\n",
            "  - Training model 129/10000\n",
            "  - Training model 130/10000\n",
            "  - Training model 131/10000\n",
            "  - Training model 132/10000\n",
            "  - Training model 133/10000\n",
            "  - Training model 134/10000\n",
            "  - Training model 135/10000\n",
            "  - Training model 136/10000\n",
            "  - Training model 137/10000\n",
            "  - Training model 138/10000\n",
            "  - Training model 139/10000\n",
            "  - Training model 140/10000\n",
            "  - Training model 141/10000\n",
            "  - Training model 142/10000\n",
            "  - Training model 143/10000\n",
            "  - Training model 144/10000\n",
            "  - Training model 145/10000\n",
            "  - Training model 146/10000\n",
            "  - Training model 147/10000\n",
            "  - Training model 148/10000\n",
            "  - Training model 149/10000\n",
            "  - Training model 150/10000\n",
            "  - Training model 151/10000\n",
            "  - Training model 152/10000\n",
            "  - Training model 153/10000\n",
            "  - Training model 154/10000\n",
            "  - Training model 155/10000\n",
            "  - Training model 156/10000\n",
            "  - Training model 157/10000\n",
            "  - Training model 158/10000\n",
            "  - Training model 159/10000\n",
            "  - Training model 160/10000\n",
            "  - Training model 161/10000\n",
            "  - Training model 162/10000\n",
            "  - Training model 163/10000\n",
            "  - Training model 164/10000\n",
            "  - Training model 165/10000\n",
            "  - Training model 166/10000\n",
            "  - Training model 167/10000\n",
            "  - Training model 168/10000\n",
            "  - Training model 169/10000\n",
            "  - Training model 170/10000\n",
            "  - Training model 171/10000\n",
            "  - Training model 172/10000\n",
            "  - Training model 173/10000\n",
            "  - Training model 174/10000\n",
            "  - Training model 175/10000\n",
            "  - Training model 176/10000\n",
            "  - Training model 177/10000\n",
            "  - Training model 178/10000\n",
            "  - Training model 179/10000\n",
            "  - Training model 180/10000\n",
            "  - Training model 181/10000\n",
            "  - Training model 182/10000\n",
            "  - Training model 183/10000\n",
            "  - Training model 184/10000\n",
            "  - Training model 185/10000\n",
            "  - Training model 186/10000\n",
            "  - Training model 187/10000\n",
            "  - Training model 188/10000\n",
            "  - Training model 189/10000\n",
            "  - Training model 190/10000\n",
            "  - Training model 191/10000\n",
            "  - Training model 192/10000\n",
            "  - Training model 193/10000\n",
            "  - Training model 194/10000\n",
            "  - Training model 195/10000\n",
            "  - Training model 196/10000\n",
            "  - Training model 197/10000\n",
            "  - Training model 198/10000\n",
            "  - Training model 199/10000\n",
            "  - Training model 200/10000\n",
            "  - Training model 201/10000\n",
            "  - Training model 202/10000\n",
            "  - Training model 203/10000\n",
            "  - Training model 204/10000\n",
            "  - Training model 205/10000\n",
            "  - Training model 206/10000\n",
            "  - Training model 207/10000\n",
            "  - Training model 208/10000\n",
            "  - Training model 209/10000\n",
            "  - Training model 210/10000\n",
            "  - Training model 211/10000\n",
            "  - Training model 212/10000\n",
            "  - Training model 213/10000\n",
            "  - Training model 214/10000\n",
            "  - Training model 215/10000\n",
            "  - Training model 216/10000\n",
            "  - Training model 217/10000\n",
            "  - Training model 218/10000\n",
            "  - Training model 219/10000\n",
            "  - Training model 220/10000\n",
            "  - Training model 221/10000\n",
            "  - Training model 222/10000\n",
            "  - Training model 223/10000\n",
            "  - Training model 224/10000\n",
            "  - Training model 225/10000\n",
            "  - Training model 226/10000\n",
            "  - Training model 227/10000\n",
            "  - Training model 228/10000\n",
            "  - Training model 229/10000\n",
            "  - Training model 230/10000\n",
            "  - Training model 231/10000\n",
            "  - Training model 232/10000\n",
            "  - Training model 233/10000\n",
            "  - Training model 234/10000\n",
            "  - Training model 235/10000\n",
            "  - Training model 236/10000\n",
            "  - Training model 237/10000\n",
            "  - Training model 238/10000\n",
            "  - Training model 239/10000\n",
            "  - Training model 240/10000\n",
            "  - Training model 241/10000\n",
            "  - Training model 242/10000\n",
            "  - Training model 243/10000\n",
            "  - Training model 244/10000\n",
            "  - Training model 245/10000\n",
            "  - Training model 246/10000\n",
            "  - Training model 247/10000\n",
            "  - Training model 248/10000\n",
            "  - Training model 249/10000\n",
            "  - Training model 250/10000\n",
            "  - Training model 251/10000\n",
            "  - Training model 252/10000\n",
            "  - Training model 253/10000\n",
            "  - Training model 254/10000\n",
            "  - Training model 255/10000\n",
            "  - Training model 256/10000\n",
            "  - Training model 257/10000\n",
            "  - Training model 258/10000\n",
            "  - Training model 259/10000\n",
            "  - Training model 260/10000\n",
            "  - Training model 261/10000\n",
            "  - Training model 262/10000\n",
            "  - Training model 263/10000\n",
            "  - Training model 264/10000\n",
            "  - Training model 265/10000\n",
            "  - Training model 266/10000\n",
            "  - Training model 267/10000\n",
            "  - Training model 268/10000\n",
            "  - Training model 269/10000\n",
            "  - Training model 270/10000\n",
            "  - Training model 271/10000\n",
            "  - Training model 272/10000\n",
            "  - Training model 273/10000\n",
            "  - Training model 274/10000\n",
            "  - Training model 275/10000\n",
            "  - Training model 276/10000\n",
            "  - Training model 277/10000\n",
            "  - Training model 278/10000\n",
            "  - Training model 279/10000\n",
            "  - Training model 280/10000\n",
            "  - Training model 281/10000\n",
            "  - Training model 282/10000\n",
            "  - Training model 283/10000\n",
            "  - Training model 284/10000\n",
            "  - Training model 285/10000\n",
            "  - Training model 286/10000\n",
            "  - Training model 287/10000\n",
            "  - Training model 288/10000\n",
            "  - Training model 289/10000\n",
            "  - Training model 290/10000\n",
            "  - Training model 291/10000\n",
            "  - Training model 292/10000\n",
            "  - Training model 293/10000\n",
            "  - Training model 294/10000\n",
            "  - Training model 295/10000\n",
            "  - Training model 296/10000\n",
            "  - Training model 297/10000\n",
            "  - Training model 298/10000\n",
            "  - Training model 299/10000\n",
            "  - Training model 300/10000\n",
            "  - Training model 301/10000\n",
            "  - Training model 302/10000\n",
            "  - Training model 303/10000\n",
            "  - Training model 304/10000\n",
            "  - Training model 305/10000\n",
            "  - Training model 306/10000\n",
            "  - Training model 307/10000\n",
            "  - Training model 308/10000\n",
            "  - Training model 309/10000\n",
            "  - Training model 310/10000\n",
            "  - Training model 311/10000\n",
            "  - Training model 312/10000\n",
            "  - Training model 313/10000\n",
            "  - Training model 314/10000\n",
            "  - Training model 315/10000\n",
            "  - Training model 316/10000\n",
            "  - Training model 317/10000\n",
            "  - Training model 318/10000\n",
            "  - Training model 319/10000\n",
            "  - Training model 320/10000\n",
            "  - Training model 321/10000\n",
            "  - Training model 322/10000\n",
            "  - Training model 323/10000\n",
            "  - Training model 324/10000\n",
            "  - Training model 325/10000\n",
            "  - Training model 326/10000\n",
            "  - Training model 327/10000\n",
            "  - Training model 328/10000\n",
            "  - Training model 329/10000\n",
            "  - Training model 330/10000\n",
            "  - Training model 331/10000\n",
            "  - Training model 332/10000\n",
            "  - Training model 333/10000\n",
            "  - Training model 334/10000\n",
            "  - Training model 335/10000\n",
            "  - Training model 336/10000\n",
            "  - Training model 337/10000\n",
            "  - Training model 338/10000\n",
            "  - Training model 339/10000\n",
            "  - Training model 340/10000\n",
            "  - Training model 341/10000\n",
            "  - Training model 342/10000\n",
            "  - Training model 343/10000\n",
            "  - Training model 344/10000\n",
            "  - Training model 345/10000\n",
            "  - Training model 346/10000\n",
            "  - Training model 347/10000\n",
            "  - Training model 348/10000\n",
            "  - Training model 349/10000\n",
            "  - Training model 350/10000\n",
            "  - Training model 351/10000\n",
            "  - Training model 352/10000\n",
            "  - Training model 353/10000\n",
            "  - Training model 354/10000\n",
            "  - Training model 355/10000\n",
            "  - Training model 356/10000\n",
            "  - Training model 357/10000\n",
            "  - Training model 358/10000\n",
            "  - Training model 359/10000\n",
            "  - Training model 360/10000\n",
            "  - Training model 361/10000\n",
            "  - Training model 362/10000\n",
            "  - Training model 363/10000\n",
            "  - Training model 364/10000\n",
            "  - Training model 365/10000\n",
            "  - Training model 366/10000\n",
            "  - Training model 367/10000\n",
            "  - Training model 368/10000\n",
            "  - Training model 369/10000\n",
            "  - Training model 370/10000\n",
            "  - Training model 371/10000\n",
            "  - Training model 372/10000\n",
            "  - Training model 373/10000\n",
            "  - Training model 374/10000\n",
            "  - Training model 375/10000\n",
            "  - Training model 376/10000\n",
            "  - Training model 377/10000\n",
            "  - Training model 378/10000\n",
            "  - Training model 379/10000\n",
            "  - Training model 380/10000\n",
            "  - Training model 381/10000\n",
            "  - Training model 382/10000\n",
            "  - Training model 383/10000\n",
            "  - Training model 384/10000\n",
            "  - Training model 385/10000\n",
            "  - Training model 386/10000\n",
            "  - Training model 387/10000\n",
            "  - Training model 388/10000\n",
            "  - Training model 389/10000\n",
            "  - Training model 390/10000\n",
            "  - Training model 391/10000\n",
            "  - Training model 392/10000\n",
            "  - Training model 393/10000\n",
            "  - Training model 394/10000\n",
            "  - Training model 395/10000\n",
            "  - Training model 396/10000\n",
            "  - Training model 397/10000\n",
            "  - Training model 398/10000\n",
            "  - Training model 399/10000\n",
            "  - Training model 400/10000\n",
            "  - Training model 401/10000\n",
            "  - Training model 402/10000\n",
            "  - Training model 403/10000\n",
            "  - Training model 404/10000\n",
            "  - Training model 405/10000\n",
            "  - Training model 406/10000\n",
            "  - Training model 407/10000\n",
            "  - Training model 408/10000\n",
            "  - Training model 409/10000\n",
            "  - Training model 410/10000\n",
            "  - Training model 411/10000\n",
            "  - Training model 412/10000\n",
            "  - Training model 413/10000\n",
            "  - Training model 414/10000\n",
            "  - Training model 415/10000\n",
            "  - Training model 416/10000\n",
            "  - Training model 417/10000\n",
            "  - Training model 418/10000\n",
            "  - Training model 419/10000\n",
            "  - Training model 420/10000\n",
            "  - Training model 421/10000\n",
            "  - Training model 422/10000\n",
            "  - Training model 423/10000\n",
            "  - Training model 424/10000\n",
            "  - Training model 425/10000\n",
            "  - Training model 426/10000\n",
            "  - Training model 427/10000\n",
            "  - Training model 428/10000\n",
            "  - Training model 429/10000\n",
            "  - Training model 430/10000\n",
            "  - Training model 431/10000\n",
            "  - Training model 432/10000\n",
            "  - Training model 433/10000\n",
            "  - Training model 434/10000\n",
            "  - Training model 435/10000\n",
            "  - Training model 436/10000\n",
            "  - Training model 437/10000\n",
            "  - Training model 438/10000\n",
            "  - Training model 439/10000\n",
            "  - Training model 440/10000\n",
            "  - Training model 441/10000\n",
            "  - Training model 442/10000\n",
            "  - Training model 443/10000\n",
            "  - Training model 444/10000\n",
            "  - Training model 445/10000\n",
            "  - Training model 446/10000\n",
            "  - Training model 447/10000\n",
            "  - Training model 448/10000\n",
            "  - Training model 449/10000\n",
            "  - Training model 450/10000\n",
            "  - Training model 451/10000\n",
            "  - Training model 452/10000\n",
            "  - Training model 453/10000\n",
            "  - Training model 454/10000\n",
            "  - Training model 455/10000\n",
            "  - Training model 456/10000\n",
            "  - Training model 457/10000\n",
            "  - Training model 458/10000\n",
            "  - Training model 459/10000\n",
            "  - Training model 460/10000\n",
            "  - Training model 461/10000\n",
            "  - Training model 462/10000\n",
            "  - Training model 463/10000\n",
            "  - Training model 464/10000\n",
            "  - Training model 465/10000\n",
            "  - Training model 466/10000\n",
            "  - Training model 467/10000\n",
            "  - Training model 468/10000\n",
            "  - Training model 469/10000\n",
            "  - Training model 470/10000\n",
            "  - Training model 471/10000\n",
            "  - Training model 472/10000\n",
            "  - Training model 473/10000\n",
            "  - Training model 474/10000\n",
            "  - Training model 475/10000\n",
            "  - Training model 476/10000\n",
            "  - Training model 477/10000\n",
            "  - Training model 478/10000\n",
            "  - Training model 479/10000\n",
            "  - Training model 480/10000\n",
            "  - Training model 481/10000\n",
            "  - Training model 482/10000\n",
            "  - Training model 483/10000\n",
            "  - Training model 484/10000\n",
            "  - Training model 485/10000\n",
            "  - Training model 486/10000\n",
            "  - Training model 487/10000\n",
            "  - Training model 488/10000\n",
            "  - Training model 489/10000\n",
            "  - Training model 490/10000\n",
            "  - Training model 491/10000\n",
            "  - Training model 492/10000\n",
            "  - Training model 493/10000\n",
            "  - Training model 494/10000\n",
            "  - Training model 495/10000\n",
            "  - Training model 496/10000\n",
            "  - Training model 497/10000\n",
            "  - Training model 498/10000\n",
            "  - Training model 499/10000\n",
            "  - Training model 500/10000\n",
            "  - Training model 501/10000\n",
            "  - Training model 502/10000\n",
            "  - Training model 503/10000\n",
            "  - Training model 504/10000\n",
            "  - Training model 505/10000\n",
            "  - Training model 506/10000\n",
            "  - Training model 507/10000\n",
            "  - Training model 508/10000\n",
            "  - Training model 509/10000\n",
            "  - Training model 510/10000\n",
            "  - Training model 511/10000\n",
            "  - Training model 512/10000\n",
            "  - Training model 513/10000\n",
            "  - Training model 514/10000\n",
            "  - Training model 515/10000\n",
            "  - Training model 516/10000\n",
            "  - Training model 517/10000\n",
            "  - Training model 518/10000\n",
            "  - Training model 519/10000\n",
            "  - Training model 520/10000\n",
            "  - Training model 521/10000\n",
            "  - Training model 522/10000\n",
            "  - Training model 523/10000\n",
            "  - Training model 524/10000\n",
            "  - Training model 525/10000\n",
            "  - Training model 526/10000\n",
            "  - Training model 527/10000\n",
            "  - Training model 528/10000\n",
            "  - Training model 529/10000\n",
            "  - Training model 530/10000\n",
            "  - Training model 531/10000\n",
            "  - Training model 532/10000\n",
            "  - Training model 533/10000\n",
            "  - Training model 534/10000\n",
            "  - Training model 535/10000\n",
            "  - Training model 536/10000\n",
            "  - Training model 537/10000\n",
            "  - Training model 538/10000\n",
            "  - Training model 539/10000\n",
            "  - Training model 540/10000\n",
            "  - Training model 541/10000\n",
            "  - Training model 542/10000\n",
            "  - Training model 543/10000\n",
            "  - Training model 544/10000\n",
            "  - Training model 545/10000\n",
            "  - Training model 546/10000\n",
            "  - Training model 547/10000\n",
            "  - Training model 548/10000\n",
            "  - Training model 549/10000\n",
            "  - Training model 550/10000\n",
            "  - Training model 551/10000\n",
            "  - Training model 552/10000\n",
            "  - Training model 553/10000\n",
            "  - Training model 554/10000\n",
            "  - Training model 555/10000\n",
            "  - Training model 556/10000\n",
            "  - Training model 557/10000\n",
            "  - Training model 558/10000\n",
            "  - Training model 559/10000\n",
            "  - Training model 560/10000\n",
            "  - Training model 561/10000\n",
            "  - Training model 562/10000\n",
            "  - Training model 563/10000\n",
            "  - Training model 564/10000\n",
            "  - Training model 565/10000\n",
            "  - Training model 566/10000\n",
            "  - Training model 567/10000\n",
            "  - Training model 568/10000\n",
            "  - Training model 569/10000\n",
            "  - Training model 570/10000\n",
            "  - Training model 571/10000\n",
            "  - Training model 572/10000\n",
            "  - Training model 573/10000\n",
            "  - Training model 574/10000\n",
            "  - Training model 575/10000\n",
            "  - Training model 576/10000\n",
            "  - Training model 577/10000\n",
            "  - Training model 578/10000\n",
            "  - Training model 579/10000\n",
            "  - Training model 580/10000\n",
            "  - Training model 581/10000\n",
            "  - Training model 582/10000\n",
            "  - Training model 583/10000\n",
            "  - Training model 584/10000\n",
            "  - Training model 585/10000\n",
            "  - Training model 586/10000\n",
            "  - Training model 587/10000\n",
            "  - Training model 588/10000\n",
            "  - Training model 589/10000\n",
            "  - Training model 590/10000\n",
            "  - Training model 591/10000\n",
            "  - Training model 592/10000\n",
            "  - Training model 593/10000\n",
            "  - Training model 594/10000\n",
            "  - Training model 595/10000\n",
            "  - Training model 596/10000\n",
            "  - Training model 597/10000\n",
            "  - Training model 598/10000\n",
            "  - Training model 599/10000\n",
            "  - Training model 600/10000\n",
            "  - Training model 601/10000\n",
            "  - Training model 602/10000\n",
            "  - Training model 603/10000\n",
            "  - Training model 604/10000\n",
            "  - Training model 605/10000\n",
            "  - Training model 606/10000\n",
            "  - Training model 607/10000\n",
            "  - Training model 608/10000\n",
            "  - Training model 609/10000\n",
            "  - Training model 610/10000\n",
            "  - Training model 611/10000\n",
            "  - Training model 612/10000\n",
            "  - Training model 613/10000\n",
            "  - Training model 614/10000\n",
            "  - Training model 615/10000\n",
            "  - Training model 616/10000\n",
            "  - Training model 617/10000\n",
            "  - Training model 618/10000\n",
            "  - Training model 619/10000\n",
            "  - Training model 620/10000\n",
            "  - Training model 621/10000\n",
            "  - Training model 622/10000\n",
            "  - Training model 623/10000\n",
            "  - Training model 624/10000\n",
            "  - Training model 625/10000\n",
            "  - Training model 626/10000\n",
            "  - Training model 627/10000\n",
            "  - Training model 628/10000\n",
            "  - Training model 629/10000\n",
            "  - Training model 630/10000\n",
            "  - Training model 631/10000\n",
            "  - Training model 632/10000\n",
            "  - Training model 633/10000\n",
            "  - Training model 634/10000\n",
            "  - Training model 635/10000\n",
            "  - Training model 636/10000\n",
            "  - Training model 637/10000\n",
            "  - Training model 638/10000\n",
            "  - Training model 639/10000\n",
            "  - Training model 640/10000\n",
            "  - Training model 641/10000\n",
            "  - Training model 642/10000\n",
            "  - Training model 643/10000\n",
            "  - Training model 644/10000\n",
            "  - Training model 645/10000\n",
            "  - Training model 646/10000\n",
            "  - Training model 647/10000\n",
            "  - Training model 648/10000\n",
            "  - Training model 649/10000\n",
            "  - Training model 650/10000\n",
            "  - Training model 651/10000\n",
            "  - Training model 652/10000\n",
            "  - Training model 653/10000\n",
            "  - Training model 654/10000\n",
            "  - Training model 655/10000\n",
            "  - Training model 656/10000\n",
            "  - Training model 657/10000\n",
            "  - Training model 658/10000\n",
            "  - Training model 659/10000\n",
            "  - Training model 660/10000\n",
            "  - Training model 661/10000\n",
            "  - Training model 662/10000\n",
            "  - Training model 663/10000\n",
            "  - Training model 664/10000\n",
            "  - Training model 665/10000\n",
            "  - Training model 666/10000\n",
            "  - Training model 667/10000\n",
            "  - Training model 668/10000\n",
            "  - Training model 669/10000\n",
            "  - Training model 670/10000\n",
            "  - Training model 671/10000\n",
            "  - Training model 672/10000\n",
            "  - Training model 673/10000\n",
            "  - Training model 674/10000\n",
            "  - Training model 675/10000\n",
            "  - Training model 676/10000\n",
            "  - Training model 677/10000\n",
            "  - Training model 678/10000\n",
            "  - Training model 679/10000\n",
            "  - Training model 680/10000\n",
            "  - Training model 681/10000\n",
            "  - Training model 682/10000\n",
            "  - Training model 683/10000\n",
            "  - Training model 684/10000\n",
            "  - Training model 685/10000\n",
            "  - Training model 686/10000\n",
            "  - Training model 687/10000\n",
            "  - Training model 688/10000\n",
            "  - Training model 689/10000\n",
            "  - Training model 690/10000\n",
            "  - Training model 691/10000\n",
            "  - Training model 692/10000\n",
            "  - Training model 693/10000\n",
            "  - Training model 694/10000\n",
            "  - Training model 695/10000\n",
            "  - Training model 696/10000\n",
            "  - Training model 697/10000\n",
            "  - Training model 698/10000\n",
            "  - Training model 699/10000\n",
            "  - Training model 700/10000\n",
            "  - Training model 701/10000\n",
            "  - Training model 702/10000\n",
            "  - Training model 703/10000\n",
            "  - Training model 704/10000\n",
            "  - Training model 705/10000\n",
            "  - Training model 706/10000\n",
            "  - Training model 707/10000\n",
            "  - Training model 708/10000\n",
            "  - Training model 709/10000\n",
            "  - Training model 710/10000\n",
            "  - Training model 711/10000\n",
            "  - Training model 712/10000\n",
            "  - Training model 713/10000\n",
            "  - Training model 714/10000\n",
            "  - Training model 715/10000\n",
            "  - Training model 716/10000\n",
            "  - Training model 717/10000\n",
            "  - Training model 718/10000\n",
            "  - Training model 719/10000\n",
            "  - Training model 720/10000\n",
            "  - Training model 721/10000\n",
            "  - Training model 722/10000\n",
            "  - Training model 723/10000\n",
            "  - Training model 724/10000\n",
            "  - Training model 725/10000\n",
            "  - Training model 726/10000\n",
            "  - Training model 727/10000\n",
            "  - Training model 728/10000\n",
            "  - Training model 729/10000\n",
            "  - Training model 730/10000\n",
            "  - Training model 731/10000\n",
            "  - Training model 732/10000\n",
            "  - Training model 733/10000\n",
            "  - Training model 734/10000\n",
            "  - Training model 735/10000\n",
            "  - Training model 736/10000\n",
            "  - Training model 737/10000\n",
            "  - Training model 738/10000\n",
            "  - Training model 739/10000\n",
            "  - Training model 740/10000\n",
            "  - Training model 741/10000\n",
            "  - Training model 742/10000\n",
            "  - Training model 743/10000\n",
            "  - Training model 744/10000\n",
            "  - Training model 745/10000\n",
            "  - Training model 746/10000\n",
            "  - Training model 747/10000\n",
            "  - Training model 748/10000\n",
            "  - Training model 749/10000\n",
            "  - Training model 750/10000\n",
            "  - Training model 751/10000\n",
            "  - Training model 752/10000\n",
            "  - Training model 753/10000\n",
            "  - Training model 754/10000\n",
            "  - Training model 755/10000\n",
            "  - Training model 756/10000\n",
            "  - Training model 757/10000\n",
            "  - Training model 758/10000\n",
            "  - Training model 759/10000\n",
            "  - Training model 760/10000\n",
            "  - Training model 761/10000\n",
            "  - Training model 762/10000\n",
            "  - Training model 763/10000\n",
            "  - Training model 764/10000\n",
            "  - Training model 765/10000\n",
            "  - Training model 766/10000\n",
            "  - Training model 767/10000\n",
            "  - Training model 768/10000\n",
            "  - Training model 769/10000\n",
            "  - Training model 770/10000\n",
            "  - Training model 771/10000\n",
            "  - Training model 772/10000\n",
            "  - Training model 773/10000\n",
            "  - Training model 774/10000\n",
            "  - Training model 775/10000\n",
            "  - Training model 776/10000\n",
            "  - Training model 777/10000\n",
            "  - Training model 778/10000\n",
            "  - Training model 779/10000\n",
            "  - Training model 780/10000\n",
            "  - Training model 781/10000\n",
            "  - Training model 782/10000\n",
            "  - Training model 783/10000\n",
            "  - Training model 784/10000\n",
            "  - Training model 785/10000\n",
            "  - Training model 786/10000\n",
            "  - Training model 787/10000\n",
            "  - Training model 788/10000\n",
            "  - Training model 789/10000\n",
            "  - Training model 790/10000\n",
            "  - Training model 791/10000\n",
            "  - Training model 792/10000\n",
            "  - Training model 793/10000\n",
            "  - Training model 794/10000\n",
            "  - Training model 795/10000\n",
            "  - Training model 796/10000\n",
            "  - Training model 797/10000\n",
            "  - Training model 798/10000\n",
            "  - Training model 799/10000\n",
            "  - Training model 800/10000\n",
            "  - Training model 801/10000\n",
            "  - Training model 802/10000\n",
            "  - Training model 803/10000\n",
            "  - Training model 804/10000\n",
            "  - Training model 805/10000\n",
            "  - Training model 806/10000\n",
            "  - Training model 807/10000\n",
            "  - Training model 808/10000\n",
            "  - Training model 809/10000\n",
            "  - Training model 810/10000\n",
            "  - Training model 811/10000\n",
            "  - Training model 812/10000\n",
            "  - Training model 813/10000\n",
            "  - Training model 814/10000\n",
            "  - Training model 815/10000\n",
            "  - Training model 816/10000\n",
            "  - Training model 817/10000\n",
            "  - Training model 818/10000\n",
            "  - Training model 819/10000\n",
            "  - Training model 820/10000\n",
            "  - Training model 821/10000\n",
            "  - Training model 822/10000\n",
            "  - Training model 823/10000\n",
            "  - Training model 824/10000\n",
            "  - Training model 825/10000\n",
            "  - Training model 826/10000\n",
            "  - Training model 827/10000\n",
            "  - Training model 828/10000\n",
            "  - Training model 829/10000\n",
            "  - Training model 830/10000\n",
            "  - Training model 831/10000\n",
            "  - Training model 832/10000\n",
            "  - Training model 833/10000\n",
            "  - Training model 834/10000\n",
            "  - Training model 835/10000\n",
            "  - Training model 836/10000\n",
            "  - Training model 837/10000\n",
            "  - Training model 838/10000\n",
            "  - Training model 839/10000\n",
            "  - Training model 840/10000\n",
            "  - Training model 841/10000\n",
            "  - Training model 842/10000\n",
            "  - Training model 843/10000\n",
            "  - Training model 844/10000\n",
            "  - Training model 845/10000\n",
            "  - Training model 846/10000\n",
            "  - Training model 847/10000\n",
            "  - Training model 848/10000\n",
            "  - Training model 849/10000\n",
            "  - Training model 850/10000\n",
            "  - Training model 851/10000\n",
            "  - Training model 852/10000\n",
            "  - Training model 853/10000\n",
            "  - Training model 854/10000\n",
            "  - Training model 855/10000\n",
            "  - Training model 856/10000\n",
            "  - Training model 857/10000\n",
            "  - Training model 858/10000\n",
            "  - Training model 859/10000\n",
            "  - Training model 860/10000\n",
            "  - Training model 861/10000\n",
            "  - Training model 862/10000\n",
            "  - Training model 863/10000\n",
            "  - Training model 864/10000\n",
            "  - Training model 865/10000\n",
            "  - Training model 866/10000\n",
            "  - Training model 867/10000\n",
            "  - Training model 868/10000\n",
            "  - Training model 869/10000\n",
            "  - Training model 870/10000\n",
            "  - Training model 871/10000\n",
            "  - Training model 872/10000\n",
            "  - Training model 873/10000\n",
            "  - Training model 874/10000\n",
            "  - Training model 875/10000\n",
            "  - Training model 876/10000\n",
            "  - Training model 877/10000\n",
            "  - Training model 878/10000\n",
            "  - Training model 879/10000\n",
            "  - Training model 880/10000\n",
            "  - Training model 881/10000\n",
            "  - Training model 882/10000\n",
            "  - Training model 883/10000\n",
            "  - Training model 884/10000\n",
            "  - Training model 885/10000\n",
            "  - Training model 886/10000\n",
            "  - Training model 887/10000\n",
            "  - Training model 888/10000\n",
            "  - Training model 889/10000\n",
            "  - Training model 890/10000\n",
            "  - Training model 891/10000\n",
            "  - Training model 892/10000\n",
            "  - Training model 893/10000\n",
            "  - Training model 894/10000\n",
            "  - Training model 895/10000\n",
            "  - Training model 896/10000\n",
            "  - Training model 897/10000\n",
            "  - Training model 898/10000\n",
            "  - Training model 899/10000\n",
            "  - Training model 900/10000\n",
            "  - Training model 901/10000\n",
            "  - Training model 902/10000\n",
            "  - Training model 903/10000\n",
            "  - Training model 904/10000\n",
            "  - Training model 905/10000\n",
            "  - Training model 906/10000\n",
            "  - Training model 907/10000\n",
            "  - Training model 908/10000\n",
            "  - Training model 909/10000\n",
            "  - Training model 910/10000\n",
            "  - Training model 911/10000\n",
            "  - Training model 912/10000\n",
            "  - Training model 913/10000\n",
            "  - Training model 914/10000\n",
            "  - Training model 915/10000\n",
            "  - Training model 916/10000\n",
            "  - Training model 917/10000\n",
            "  - Training model 918/10000\n",
            "  - Training model 919/10000\n",
            "  - Training model 920/10000\n",
            "  - Training model 921/10000\n",
            "  - Training model 922/10000\n",
            "  - Training model 923/10000\n",
            "  - Training model 924/10000\n",
            "  - Training model 925/10000\n",
            "  - Training model 926/10000\n",
            "  - Training model 927/10000\n",
            "  - Training model 928/10000\n",
            "  - Training model 929/10000\n",
            "  - Training model 930/10000\n",
            "  - Training model 931/10000\n",
            "  - Training model 932/10000\n",
            "  - Training model 933/10000\n",
            "  - Training model 934/10000\n",
            "  - Training model 935/10000\n",
            "  - Training model 936/10000\n",
            "  - Training model 937/10000\n",
            "  - Training model 938/10000\n",
            "  - Training model 939/10000\n",
            "  - Training model 940/10000\n",
            "  - Training model 941/10000\n",
            "  - Training model 942/10000\n",
            "  - Training model 943/10000\n",
            "  - Training model 944/10000\n",
            "  - Training model 945/10000\n",
            "  - Training model 946/10000\n",
            "  - Training model 947/10000\n",
            "  - Training model 948/10000\n",
            "  - Training model 949/10000\n",
            "  - Training model 950/10000\n",
            "  - Training model 951/10000\n",
            "  - Training model 952/10000\n",
            "  - Training model 953/10000\n",
            "  - Training model 954/10000\n",
            "  - Training model 955/10000\n",
            "  - Training model 956/10000\n",
            "  - Training model 957/10000\n",
            "  - Training model 958/10000\n",
            "  - Training model 959/10000\n",
            "  - Training model 960/10000\n",
            "  - Training model 961/10000\n",
            "  - Training model 962/10000\n",
            "  - Training model 963/10000\n",
            "  - Training model 964/10000\n",
            "  - Training model 965/10000\n",
            "  - Training model 966/10000\n",
            "  - Training model 967/10000\n",
            "  - Training model 968/10000\n",
            "  - Training model 969/10000\n",
            "  - Training model 970/10000\n",
            "  - Training model 971/10000\n",
            "  - Training model 972/10000\n",
            "  - Training model 973/10000\n",
            "  - Training model 974/10000\n",
            "  - Training model 975/10000\n",
            "  - Training model 976/10000\n",
            "  - Training model 977/10000\n",
            "  - Training model 978/10000\n",
            "  - Training model 979/10000\n",
            "  - Training model 980/10000\n",
            "  - Training model 981/10000\n",
            "  - Training model 982/10000\n",
            "  - Training model 983/10000\n",
            "  - Training model 984/10000\n",
            "  - Training model 985/10000\n",
            "  - Training model 986/10000\n",
            "  - Training model 987/10000\n",
            "  - Training model 988/10000\n",
            "  - Training model 989/10000\n",
            "  - Training model 990/10000\n",
            "  - Training model 991/10000\n",
            "  - Training model 992/10000\n",
            "  - Training model 993/10000\n",
            "  - Training model 994/10000\n",
            "  - Training model 995/10000\n",
            "  - Training model 996/10000\n",
            "  - Training model 997/10000\n",
            "  - Training model 998/10000\n",
            "  - Training model 999/10000\n",
            "  - Training model 1000/10000\n",
            "  - Training model 1001/10000\n",
            "  - Training model 1002/10000\n",
            "  - Training model 1003/10000\n",
            "  - Training model 1004/10000\n",
            "  - Training model 1005/10000\n",
            "  - Training model 1006/10000\n",
            "  - Training model 1007/10000\n",
            "  - Training model 1008/10000\n",
            "  - Training model 1009/10000\n",
            "  - Training model 1010/10000\n",
            "  - Training model 1011/10000\n",
            "  - Training model 1012/10000\n",
            "  - Training model 1013/10000\n",
            "  - Training model 1014/10000\n",
            "  - Training model 1015/10000\n",
            "  - Training model 1016/10000\n",
            "  - Training model 1017/10000\n",
            "  - Training model 1018/10000\n",
            "  - Training model 1019/10000\n",
            "  - Training model 1020/10000\n",
            "  - Training model 1021/10000\n",
            "  - Training model 1022/10000\n",
            "  - Training model 1023/10000\n",
            "  - Training model 1024/10000\n",
            "  - Training model 1025/10000\n",
            "  - Training model 1026/10000\n",
            "  - Training model 1027/10000\n",
            "  - Training model 1028/10000\n",
            "  - Training model 1029/10000\n",
            "  - Training model 1030/10000\n",
            "  - Training model 1031/10000\n",
            "  - Training model 1032/10000\n",
            "  - Training model 1033/10000\n",
            "  - Training model 1034/10000\n",
            "  - Training model 1035/10000\n",
            "  - Training model 1036/10000\n",
            "  - Training model 1037/10000\n",
            "  - Training model 1038/10000\n",
            "  - Training model 1039/10000\n",
            "  - Training model 1040/10000\n",
            "  - Training model 1041/10000\n",
            "  - Training model 1042/10000\n",
            "  - Training model 1043/10000\n",
            "  - Training model 1044/10000\n",
            "  - Training model 1045/10000\n",
            "  - Training model 1046/10000\n",
            "  - Training model 1047/10000\n",
            "  - Training model 1048/10000\n",
            "  - Training model 1049/10000\n",
            "  - Training model 1050/10000\n",
            "  - Training model 1051/10000\n",
            "  - Training model 1052/10000\n",
            "  - Training model 1053/10000\n",
            "  - Training model 1054/10000\n",
            "  - Training model 1055/10000\n",
            "  - Training model 1056/10000\n",
            "  - Training model 1057/10000\n",
            "  - Training model 1058/10000\n",
            "  - Training model 1059/10000\n",
            "  - Training model 1060/10000\n",
            "  - Training model 1061/10000\n",
            "  - Training model 1062/10000\n",
            "  - Training model 1063/10000\n",
            "  - Training model 1064/10000\n",
            "  - Training model 1065/10000\n",
            "  - Training model 1066/10000\n",
            "  - Training model 1067/10000\n",
            "  - Training model 1068/10000\n",
            "  - Training model 1069/10000\n",
            "  - Training model 1070/10000\n",
            "  - Training model 1071/10000\n",
            "  - Training model 1072/10000\n",
            "  - Training model 1073/10000\n",
            "  - Training model 1074/10000\n",
            "  - Training model 1075/10000\n",
            "  - Training model 1076/10000\n",
            "  - Training model 1077/10000\n",
            "  - Training model 1078/10000\n",
            "  - Training model 1079/10000\n",
            "  - Training model 1080/10000\n",
            "  - Training model 1081/10000\n",
            "  - Training model 1082/10000\n",
            "  - Training model 1083/10000\n",
            "  - Training model 1084/10000\n",
            "  - Training model 1085/10000\n",
            "  - Training model 1086/10000\n",
            "  - Training model 1087/10000\n",
            "  - Training model 1088/10000\n",
            "  - Training model 1089/10000\n",
            "  - Training model 1090/10000\n",
            "  - Training model 1091/10000\n",
            "  - Training model 1092/10000\n",
            "  - Training model 1093/10000\n",
            "  - Training model 1094/10000\n",
            "  - Training model 1095/10000\n",
            "  - Training model 1096/10000\n",
            "  - Training model 1097/10000\n",
            "  - Training model 1098/10000\n",
            "  - Training model 1099/10000\n",
            "  - Training model 1100/10000\n",
            "  - Training model 1101/10000\n",
            "  - Training model 1102/10000\n",
            "  - Training model 1103/10000\n",
            "  - Training model 1104/10000\n",
            "  - Training model 1105/10000\n",
            "  - Training model 1106/10000\n",
            "  - Training model 1107/10000\n",
            "  - Training model 1108/10000\n",
            "  - Training model 1109/10000\n",
            "  - Training model 1110/10000\n",
            "  - Training model 1111/10000\n",
            "  - Training model 1112/10000\n",
            "  - Training model 1113/10000\n",
            "  - Training model 1114/10000\n",
            "  - Training model 1115/10000\n",
            "  - Training model 1116/10000\n",
            "  - Training model 1117/10000\n",
            "  - Training model 1118/10000\n",
            "  - Training model 1119/10000\n",
            "  - Training model 1120/10000\n",
            "  - Training model 1121/10000\n",
            "  - Training model 1122/10000\n",
            "  - Training model 1123/10000\n",
            "  - Training model 1124/10000\n",
            "  - Training model 1125/10000\n",
            "  - Training model 1126/10000\n",
            "  - Training model 1127/10000\n",
            "  - Training model 1128/10000\n",
            "  - Training model 1129/10000\n",
            "  - Training model 1130/10000\n",
            "  - Training model 1131/10000\n",
            "  - Training model 1132/10000\n",
            "  - Training model 1133/10000\n",
            "  - Training model 1134/10000\n",
            "  - Training model 1135/10000\n",
            "  - Training model 1136/10000\n",
            "  - Training model 1137/10000\n",
            "  - Training model 1138/10000\n",
            "  - Training model 1139/10000\n",
            "  - Training model 1140/10000\n",
            "  - Training model 1141/10000\n",
            "  - Training model 1142/10000\n",
            "  - Training model 1143/10000\n",
            "  - Training model 1144/10000\n",
            "  - Training model 1145/10000\n",
            "  - Training model 1146/10000\n",
            "  - Training model 1147/10000\n",
            "  - Training model 1148/10000\n",
            "  - Training model 1149/10000\n",
            "  - Training model 1150/10000\n",
            "  - Training model 1151/10000\n",
            "  - Training model 1152/10000\n",
            "  - Training model 1153/10000\n",
            "  - Training model 1154/10000\n",
            "  - Training model 1155/10000\n",
            "  - Training model 1156/10000\n",
            "  - Training model 1157/10000\n",
            "  - Training model 1158/10000\n",
            "  - Training model 1159/10000\n",
            "  - Training model 1160/10000\n",
            "  - Training model 1161/10000\n",
            "  - Training model 1162/10000\n",
            "  - Training model 1163/10000\n",
            "  - Training model 1164/10000\n",
            "  - Training model 1165/10000\n",
            "  - Training model 1166/10000\n",
            "  - Training model 1167/10000\n",
            "  - Training model 1168/10000\n",
            "  - Training model 1169/10000\n",
            "  - Training model 1170/10000\n",
            "  - Training model 1171/10000\n",
            "  - Training model 1172/10000\n",
            "  - Training model 1173/10000\n",
            "  - Training model 1174/10000\n",
            "  - Training model 1175/10000\n",
            "  - Training model 1176/10000\n",
            "  - Training model 1177/10000\n",
            "  - Training model 1178/10000\n",
            "  - Training model 1179/10000\n",
            "  - Training model 1180/10000\n",
            "  - Training model 1181/10000\n",
            "  - Training model 1182/10000\n",
            "  - Training model 1183/10000\n",
            "  - Training model 1184/10000\n",
            "  - Training model 1185/10000\n",
            "  - Training model 1186/10000\n",
            "  - Training model 1187/10000\n",
            "  - Training model 1188/10000\n",
            "  - Training model 1189/10000\n",
            "  - Training model 1190/10000\n",
            "  - Training model 1191/10000\n",
            "  - Training model 1192/10000\n",
            "  - Training model 1193/10000\n",
            "  - Training model 1194/10000\n",
            "  - Training model 1195/10000\n",
            "  - Training model 1196/10000\n",
            "  - Training model 1197/10000\n",
            "  - Training model 1198/10000\n",
            "  - Training model 1199/10000\n",
            "  - Training model 1200/10000\n",
            "  - Training model 1201/10000\n",
            "  - Training model 1202/10000\n",
            "  - Training model 1203/10000\n",
            "  - Training model 1204/10000\n",
            "  - Training model 1205/10000\n",
            "  - Training model 1206/10000\n",
            "  - Training model 1207/10000\n",
            "  - Training model 1208/10000\n",
            "  - Training model 1209/10000\n",
            "  - Training model 1210/10000\n",
            "  - Training model 1211/10000\n",
            "  - Training model 1212/10000\n",
            "  - Training model 1213/10000\n",
            "  - Training model 1214/10000\n",
            "  - Training model 1215/10000\n",
            "  - Training model 1216/10000\n",
            "  - Training model 1217/10000\n",
            "  - Training model 1218/10000\n",
            "  - Training model 1219/10000\n",
            "  - Training model 1220/10000\n",
            "  - Training model 1221/10000\n",
            "  - Training model 1222/10000\n",
            "  - Training model 1223/10000\n",
            "  - Training model 1224/10000\n",
            "  - Training model 1225/10000\n",
            "  - Training model 1226/10000\n",
            "  - Training model 1227/10000\n",
            "  - Training model 1228/10000\n",
            "  - Training model 1229/10000\n",
            "  - Training model 1230/10000\n",
            "  - Training model 1231/10000\n",
            "  - Training model 1232/10000\n",
            "  - Training model 1233/10000\n",
            "  - Training model 1234/10000\n",
            "  - Training model 1235/10000\n",
            "  - Training model 1236/10000\n",
            "  - Training model 1237/10000\n",
            "  - Training model 1238/10000\n",
            "  - Training model 1239/10000\n",
            "  - Training model 1240/10000\n",
            "  - Training model 1241/10000\n",
            "  - Training model 1242/10000\n",
            "  - Training model 1243/10000\n",
            "  - Training model 1244/10000\n",
            "  - Training model 1245/10000\n",
            "  - Training model 1246/10000\n",
            "  - Training model 1247/10000\n",
            "  - Training model 1248/10000\n",
            "  - Training model 1249/10000\n",
            "  - Training model 1250/10000\n",
            "  - Training model 1251/10000\n",
            "  - Training model 1252/10000\n",
            "  - Training model 1253/10000\n",
            "  - Training model 1254/10000\n",
            "  - Training model 1255/10000\n",
            "  - Training model 1256/10000\n",
            "  - Training model 1257/10000\n",
            "  - Training model 1258/10000\n",
            "  - Training model 1259/10000\n",
            "  - Training model 1260/10000\n",
            "  - Training model 1261/10000\n",
            "  - Training model 1262/10000\n",
            "  - Training model 1263/10000\n",
            "  - Training model 1264/10000\n",
            "  - Training model 1265/10000\n",
            "  - Training model 1266/10000\n",
            "  - Training model 1267/10000\n",
            "  - Training model 1268/10000\n",
            "  - Training model 1269/10000\n",
            "  - Training model 1270/10000\n",
            "  - Training model 1271/10000\n",
            "  - Training model 1272/10000\n",
            "  - Training model 1273/10000\n",
            "  - Training model 1274/10000\n",
            "  - Training model 1275/10000\n",
            "  - Training model 1276/10000\n",
            "  - Training model 1277/10000\n",
            "  - Training model 1278/10000\n",
            "  - Training model 1279/10000\n",
            "  - Training model 1280/10000\n",
            "  - Training model 1281/10000\n",
            "  - Training model 1282/10000\n",
            "  - Training model 1283/10000\n",
            "  - Training model 1284/10000\n",
            "  - Training model 1285/10000\n",
            "  - Training model 1286/10000\n",
            "  - Training model 1287/10000\n",
            "  - Training model 1288/10000\n",
            "  - Training model 1289/10000\n",
            "  - Training model 1290/10000\n",
            "  - Training model 1291/10000\n",
            "  - Training model 1292/10000\n",
            "  - Training model 1293/10000\n",
            "  - Training model 1294/10000\n",
            "  - Training model 1295/10000\n",
            "  - Training model 1296/10000\n",
            "  - Training model 1297/10000\n",
            "  - Training model 1298/10000\n",
            "  - Training model 1299/10000\n",
            "  - Training model 1300/10000\n",
            "  - Training model 1301/10000\n",
            "  - Training model 1302/10000\n",
            "  - Training model 1303/10000\n",
            "  - Training model 1304/10000\n",
            "  - Training model 1305/10000\n",
            "  - Training model 1306/10000\n",
            "  - Training model 1307/10000\n",
            "  - Training model 1308/10000\n",
            "  - Training model 1309/10000\n",
            "  - Training model 1310/10000\n",
            "  - Training model 1311/10000\n",
            "  - Training model 1312/10000\n",
            "  - Training model 1313/10000\n",
            "  - Training model 1314/10000\n",
            "  - Training model 1315/10000\n",
            "  - Training model 1316/10000\n",
            "  - Training model 1317/10000\n",
            "  - Training model 1318/10000\n",
            "  - Training model 1319/10000\n",
            "  - Training model 1320/10000\n",
            "  - Training model 1321/10000\n",
            "  - Training model 1322/10000\n",
            "  - Training model 1323/10000\n",
            "  - Training model 1324/10000\n",
            "  - Training model 1325/10000\n",
            "  - Training model 1326/10000\n",
            "  - Training model 1327/10000\n",
            "  - Training model 1328/10000\n",
            "  - Training model 1329/10000\n",
            "  - Training model 1330/10000\n",
            "  - Training model 1331/10000\n",
            "  - Training model 1332/10000\n",
            "  - Training model 1333/10000\n",
            "  - Training model 1334/10000\n",
            "  - Training model 1335/10000\n",
            "  - Training model 1336/10000\n",
            "  - Training model 1337/10000\n",
            "  - Training model 1338/10000\n",
            "  - Training model 1339/10000\n",
            "  - Training model 1340/10000\n",
            "  - Training model 1341/10000\n",
            "  - Training model 1342/10000\n",
            "  - Training model 1343/10000\n",
            "  - Training model 1344/10000\n",
            "  - Training model 1345/10000\n",
            "  - Training model 1346/10000\n",
            "  - Training model 1347/10000\n",
            "  - Training model 1348/10000\n",
            "  - Training model 1349/10000\n",
            "  - Training model 1350/10000\n",
            "  - Training model 1351/10000\n",
            "  - Training model 1352/10000\n",
            "  - Training model 1353/10000\n",
            "  - Training model 1354/10000\n",
            "  - Training model 1355/10000\n",
            "  - Training model 1356/10000\n",
            "  - Training model 1357/10000\n",
            "  - Training model 1358/10000\n",
            "  - Training model 1359/10000\n",
            "  - Training model 1360/10000\n",
            "  - Training model 1361/10000\n",
            "  - Training model 1362/10000\n",
            "  - Training model 1363/10000\n",
            "  - Training model 1364/10000\n",
            "  - Training model 1365/10000\n",
            "  - Training model 1366/10000\n",
            "  - Training model 1367/10000\n",
            "  - Training model 1368/10000\n",
            "  - Training model 1369/10000\n",
            "  - Training model 1370/10000\n",
            "  - Training model 1371/10000\n",
            "  - Training model 1372/10000\n",
            "  - Training model 1373/10000\n",
            "  - Training model 1374/10000\n",
            "  - Training model 1375/10000\n",
            "  - Training model 1376/10000\n",
            "  - Training model 1377/10000\n",
            "  - Training model 1378/10000\n",
            "  - Training model 1379/10000\n",
            "  - Training model 1380/10000\n",
            "  - Training model 1381/10000\n",
            "  - Training model 1382/10000\n",
            "  - Training model 1383/10000\n",
            "  - Training model 1384/10000\n",
            "  - Training model 1385/10000\n",
            "  - Training model 1386/10000\n",
            "  - Training model 1387/10000\n",
            "  - Training model 1388/10000\n",
            "  - Training model 1389/10000\n",
            "  - Training model 1390/10000\n",
            "  - Training model 1391/10000\n",
            "  - Training model 1392/10000\n",
            "  - Training model 1393/10000\n",
            "  - Training model 1394/10000\n",
            "  - Training model 1395/10000\n",
            "  - Training model 1396/10000\n",
            "  - Training model 1397/10000\n",
            "  - Training model 1398/10000\n",
            "  - Training model 1399/10000\n",
            "  - Training model 1400/10000\n",
            "  - Training model 1401/10000\n",
            "  - Training model 1402/10000\n",
            "  - Training model 1403/10000\n",
            "  - Training model 1404/10000\n",
            "  - Training model 1405/10000\n",
            "  - Training model 1406/10000\n",
            "  - Training model 1407/10000\n",
            "  - Training model 1408/10000\n",
            "  - Training model 1409/10000\n",
            "  - Training model 1410/10000\n",
            "  - Training model 1411/10000\n",
            "  - Training model 1412/10000\n",
            "  - Training model 1413/10000\n",
            "  - Training model 1414/10000\n",
            "  - Training model 1415/10000\n",
            "  - Training model 1416/10000\n",
            "  - Training model 1417/10000\n",
            "  - Training model 1418/10000\n",
            "  - Training model 1419/10000\n",
            "  - Training model 1420/10000\n",
            "  - Training model 1421/10000\n",
            "  - Training model 1422/10000\n",
            "  - Training model 1423/10000\n",
            "  - Training model 1424/10000\n",
            "  - Training model 1425/10000\n",
            "  - Training model 1426/10000\n",
            "  - Training model 1427/10000\n",
            "  - Training model 1428/10000\n",
            "  - Training model 1429/10000\n",
            "  - Training model 1430/10000\n",
            "  - Training model 1431/10000\n",
            "  - Training model 1432/10000\n",
            "  - Training model 1433/10000\n",
            "  - Training model 1434/10000\n",
            "  - Training model 1435/10000\n",
            "  - Training model 1436/10000\n",
            "  - Training model 1437/10000\n",
            "  - Training model 1438/10000\n",
            "  - Training model 1439/10000\n",
            "  - Training model 1440/10000\n",
            "  - Training model 1441/10000\n",
            "  - Training model 1442/10000\n",
            "  - Training model 1443/10000\n",
            "  - Training model 1444/10000\n",
            "  - Training model 1445/10000\n",
            "  - Training model 1446/10000\n",
            "  - Training model 1447/10000\n",
            "  - Training model 1448/10000\n",
            "  - Training model 1449/10000\n",
            "  - Training model 1450/10000\n",
            "  - Training model 1451/10000\n",
            "  - Training model 1452/10000\n",
            "  - Training model 1453/10000\n",
            "  - Training model 1454/10000\n",
            "  - Training model 1455/10000\n",
            "  - Training model 1456/10000\n",
            "  - Training model 1457/10000\n",
            "  - Training model 1458/10000\n",
            "  - Training model 1459/10000\n",
            "  - Training model 1460/10000\n",
            "  - Training model 1461/10000\n",
            "  - Training model 1462/10000\n",
            "  - Training model 1463/10000\n",
            "  - Training model 1464/10000\n",
            "  - Training model 1465/10000\n",
            "  - Training model 1466/10000\n",
            "  - Training model 1467/10000\n",
            "  - Training model 1468/10000\n",
            "  - Training model 1469/10000\n",
            "  - Training model 1470/10000\n",
            "  - Training model 1471/10000\n",
            "  - Training model 1472/10000\n",
            "  - Training model 1473/10000\n",
            "  - Training model 1474/10000\n",
            "  - Training model 1475/10000\n",
            "  - Training model 1476/10000\n",
            "  - Training model 1477/10000\n",
            "  - Training model 1478/10000\n",
            "  - Training model 1479/10000\n",
            "  - Training model 1480/10000\n",
            "  - Training model 1481/10000\n",
            "  - Training model 1482/10000\n",
            "  - Training model 1483/10000\n",
            "  - Training model 1484/10000\n",
            "  - Training model 1485/10000\n",
            "  - Training model 1486/10000\n",
            "  - Training model 1487/10000\n",
            "  - Training model 1488/10000\n",
            "  - Training model 1489/10000\n",
            "  - Training model 1490/10000\n",
            "  - Training model 1491/10000\n",
            "  - Training model 1492/10000\n",
            "  - Training model 1493/10000\n",
            "  - Training model 1494/10000\n",
            "  - Training model 1495/10000\n",
            "  - Training model 1496/10000\n",
            "  - Training model 1497/10000\n",
            "  - Training model 1498/10000\n",
            "  - Training model 1499/10000\n",
            "  - Training model 1500/10000\n",
            "  - Training model 1501/10000\n",
            "  - Training model 1502/10000\n",
            "  - Training model 1503/10000\n",
            "  - Training model 1504/10000\n",
            "  - Training model 1505/10000\n",
            "  - Training model 1506/10000\n",
            "  - Training model 1507/10000\n",
            "  - Training model 1508/10000\n",
            "  - Training model 1509/10000\n",
            "  - Training model 1510/10000\n",
            "  - Training model 1511/10000\n",
            "  - Training model 1512/10000\n",
            "  - Training model 1513/10000\n",
            "  - Training model 1514/10000\n",
            "  - Training model 1515/10000\n",
            "  - Training model 1516/10000\n",
            "  - Training model 1517/10000\n",
            "  - Training model 1518/10000\n",
            "  - Training model 1519/10000\n",
            "  - Training model 1520/10000\n",
            "  - Training model 1521/10000\n",
            "  - Training model 1522/10000\n",
            "  - Training model 1523/10000\n",
            "  - Training model 1524/10000\n",
            "  - Training model 1525/10000\n",
            "  - Training model 1526/10000\n",
            "  - Training model 1527/10000\n",
            "  - Training model 1528/10000\n",
            "  - Training model 1529/10000\n",
            "  - Training model 1530/10000\n",
            "  - Training model 1531/10000\n",
            "  - Training model 1532/10000\n",
            "  - Training model 1533/10000\n",
            "  - Training model 1534/10000\n",
            "  - Training model 1535/10000\n",
            "  - Training model 1536/10000\n",
            "  - Training model 1537/10000\n",
            "  - Training model 1538/10000\n",
            "  - Training model 1539/10000\n",
            "  - Training model 1540/10000\n",
            "  - Training model 1541/10000\n",
            "  - Training model 1542/10000\n",
            "  - Training model 1543/10000\n",
            "  - Training model 1544/10000\n",
            "  - Training model 1545/10000\n",
            "  - Training model 1546/10000\n",
            "  - Training model 1547/10000\n",
            "  - Training model 1548/10000\n",
            "  - Training model 1549/10000\n",
            "  - Training model 1550/10000\n",
            "  - Training model 1551/10000\n",
            "  - Training model 1552/10000\n",
            "  - Training model 1553/10000\n",
            "  - Training model 1554/10000\n",
            "  - Training model 1555/10000\n",
            "  - Training model 1556/10000\n",
            "  - Training model 1557/10000\n",
            "  - Training model 1558/10000\n",
            "  - Training model 1559/10000\n",
            "  - Training model 1560/10000\n",
            "  - Training model 1561/10000\n",
            "  - Training model 1562/10000\n",
            "  - Training model 1563/10000\n",
            "  - Training model 1564/10000\n",
            "  - Training model 1565/10000\n",
            "  - Training model 1566/10000\n",
            "  - Training model 1567/10000\n",
            "  - Training model 1568/10000\n",
            "  - Training model 1569/10000\n",
            "  - Training model 1570/10000\n",
            "  - Training model 1571/10000\n",
            "  - Training model 1572/10000\n",
            "  - Training model 1573/10000\n",
            "  - Training model 1574/10000\n",
            "  - Training model 1575/10000\n",
            "  - Training model 1576/10000\n",
            "  - Training model 1577/10000\n",
            "  - Training model 1578/10000\n",
            "  - Training model 1579/10000\n",
            "  - Training model 1580/10000\n",
            "  - Training model 1581/10000\n",
            "  - Training model 1582/10000\n",
            "  - Training model 1583/10000\n",
            "  - Training model 1584/10000\n",
            "  - Training model 1585/10000\n",
            "  - Training model 1586/10000\n",
            "  - Training model 1587/10000\n",
            "  - Training model 1588/10000\n",
            "  - Training model 1589/10000\n",
            "  - Training model 1590/10000\n",
            "  - Training model 1591/10000\n",
            "  - Training model 1592/10000\n",
            "  - Training model 1593/10000\n",
            "  - Training model 1594/10000\n",
            "  - Training model 1595/10000\n",
            "  - Training model 1596/10000\n",
            "  - Training model 1597/10000\n",
            "  - Training model 1598/10000\n",
            "  - Training model 1599/10000\n",
            "  - Training model 1600/10000\n",
            "  - Training model 1601/10000\n",
            "  - Training model 1602/10000\n",
            "  - Training model 1603/10000\n",
            "  - Training model 1604/10000\n",
            "  - Training model 1605/10000\n",
            "  - Training model 1606/10000\n",
            "  - Training model 1607/10000\n",
            "  - Training model 1608/10000\n",
            "  - Training model 1609/10000\n",
            "  - Training model 1610/10000\n",
            "  - Training model 1611/10000\n",
            "  - Training model 1612/10000\n",
            "  - Training model 1613/10000\n",
            "  - Training model 1614/10000\n",
            "  - Training model 1615/10000\n",
            "  - Training model 1616/10000\n",
            "  - Training model 1617/10000\n",
            "  - Training model 1618/10000\n",
            "  - Training model 1619/10000\n",
            "  - Training model 1620/10000\n",
            "  - Training model 1621/10000\n",
            "  - Training model 1622/10000\n",
            "  - Training model 1623/10000\n",
            "  - Training model 1624/10000\n",
            "  - Training model 1625/10000\n",
            "  - Training model 1626/10000\n",
            "  - Training model 1627/10000\n",
            "  - Training model 1628/10000\n",
            "  - Training model 1629/10000\n",
            "  - Training model 1630/10000\n",
            "  - Training model 1631/10000\n",
            "  - Training model 1632/10000\n",
            "  - Training model 1633/10000\n",
            "  - Training model 1634/10000\n",
            "  - Training model 1635/10000\n",
            "  - Training model 1636/10000\n",
            "  - Training model 1637/10000\n",
            "  - Training model 1638/10000\n",
            "  - Training model 1639/10000\n",
            "  - Training model 1640/10000\n",
            "  - Training model 1641/10000\n",
            "  - Training model 1642/10000\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 2.12 MiB is free. Process 6393 has 14.74 GiB memory in use. Of the allocated memory 13.39 GiB is allocated by PyTorch, and 1.22 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-59-516918310.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;31m# ====== Run Evolution Training ======\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m best_model = evolution_training_until_one(\n\u001b[0m\u001b[1;32m    182\u001b[0m     \u001b[0mpopulation_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m    \u001b[0;31m# You can adjust this as needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0msurvival_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-59-516918310.py\u001b[0m in \u001b[0;36mevolution_training_until_one\u001b[0;34m(population_size, survival_rate, epochs_per_gen, log_every_batches)\u001b[0m\n\u001b[1;32m    148\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"  - Training model {i+1}/{len(population)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs_per_gen\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m                 \u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlog_every_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0;31m# Evaluate all models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-59-516918310.py\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, optimizer, criterion, dataloader, model_id, epoch_num, log_every)\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_idx\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlog_every\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m                             )\n\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m_use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"differentiable\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    242\u001b[0m             )\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m             adam(\n\u001b[0m\u001b[1;32m    245\u001b[0m                 \u001b[0mparams_with_grad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m                 \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mmaybe_fallback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    152\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mdisabled_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_fallback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    874\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_single_tensor_adam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 876\u001b[0;31m     func(\n\u001b[0m\u001b[1;32m    877\u001b[0m         \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m         \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36m_multi_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    701\u001b[0m                 \u001b[0mexp_avg_sq_sqrt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_foreach_sqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_max_exp_avg_sqs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m                 \u001b[0mexp_avg_sq_sqrt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_foreach_sqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_exp_avg_sqs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_foreach_div_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq_sqrt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias_correction2_sqrt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 2.12 MiB is free. Process 6393 has 14.74 GiB memory in use. Of the allocated memory 13.39 GiB is allocated by PyTorch, and 1.22 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        }
      ],
      "source": [
        "# Modified version of your script to use a small CNN instead of MLP\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import Omniglot\n",
        "import torchvision.transforms as transforms\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "import random\n",
        "\n",
        "# ====== Setup ======\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "random.seed(42)\n",
        "\n",
        "# ====== Load Omniglot Dataset ======\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((28, 28)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "train_dataset = Omniglot(root='./data', background=True, download=True, transform=transform)\n",
        "test_dataset = Omniglot(root='./data', background=False, download=True, transform=transform)\n",
        "\n",
        "full_data = train_dataset + test_dataset\n",
        "\n",
        "X, y = [], []\n",
        "for img, label in full_data:\n",
        "    X.append(img.numpy())\n",
        "    y.append(label)\n",
        "\n",
        "X = np.stack(X)\n",
        "y = np.array(y)\n",
        "\n",
        "max_classes = 50\n",
        "mask = y < max_classes\n",
        "X = X[mask]\n",
        "y = y[mask]\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "X_trainval, X_test, y_trainval, y_test = train_test_split(\n",
        "    X, y_encoded, test_size=0.15, random_state=42, stratify=y_encoded)\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_trainval, y_trainval, test_size=0.1765, random_state=42, stratify=y_trainval)\n",
        "\n",
        "X_train_t = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_t = torch.tensor(y_train, dtype=torch.long)\n",
        "X_val_t = torch.tensor(X_val, dtype=torch.float32)\n",
        "y_val_t = torch.tensor(y_val, dtype=torch.long)\n",
        "X_test_t = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test_t = torch.tensor(y_test, dtype=torch.long)\n",
        "\n",
        "batch_size = 64\n",
        "train_loader = DataLoader(torch.utils.data.TensorDataset(X_train_t, y_train_t), batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(torch.utils.data.TensorDataset(X_val_t, y_val_t), batch_size=batch_size)\n",
        "test_loader = DataLoader(torch.utils.data.TensorDataset(X_test_t, y_test_t), batch_size=batch_size)\n",
        "\n",
        "# ====== Define CNN Model ======\n",
        "class SmallCNN(nn.Module):\n",
        "    def __init__(self, num_classes=max_classes):\n",
        "        super(SmallCNN, self).__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(64 * 7 * 7, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(128, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "# ====== Evaluation function ======\n",
        "def evaluate_model(model, dataloader):\n",
        "    model.eval()\n",
        "    all_preds, all_targets = [], []\n",
        "    with torch.no_grad():\n",
        "        for xb, yb in dataloader:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            xb = xb.view(-1, 1, 28, 28)\n",
        "            preds = torch.argmax(model(xb), dim=1)\n",
        "            all_preds.append(preds.cpu().numpy())\n",
        "            all_targets.append(yb.cpu().numpy())\n",
        "    return accuracy_score(np.concatenate(all_targets), np.concatenate(all_preds))\n",
        "\n",
        "# ====== Training function ======\n",
        "def train_one_epoch(model, optimizer, criterion, dataloader, model_id=None, epoch_num=None, log_every=100):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for batch_idx, (xb, yb) in enumerate(dataloader, 1):\n",
        "        xb, yb = xb.to(device), yb.to(device)\n",
        "        xb = xb.view(-1, 1, 28, 28)\n",
        "        optimizer.zero_grad()\n",
        "        loss = criterion(model(xb), yb)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "        if batch_idx % log_every == 0:\n",
        "            avg_loss = running_loss / log_every\n",
        "            running_loss = 0.0\n",
        "            print(f\"Model {model_id} - Epoch {epoch_num} - Batch {batch_idx}/{len(dataloader)} - Loss: {avg_loss:.4f}\")\n",
        "\n",
        "# ====== Evolutionary Training ======\n",
        "def evolution_training_until_one(population_size=10, survival_rate=0.6, epochs_per_gen=10, log_every_batches=100):\n",
        "    population, optimizers = [], []\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    for _ in range(population_size):\n",
        "        model = SmallCNN().to(device)\n",
        "        optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "        population.append(model)\n",
        "        optimizers.append(optimizer)\n",
        "\n",
        "    best_model, best_optimizer, best_score = None, None, -float('inf')\n",
        "    generation = 0\n",
        "\n",
        "    while len(population) > 1:\n",
        "        generation += 1\n",
        "        print(f\"\\nðŸŒ± Generation {generation} | Population size: {len(population)}\")\n",
        "\n",
        "        for i, (model, optimizer) in enumerate(zip(population, optimizers)):\n",
        "            for epoch in range(1, epochs_per_gen + 1):\n",
        "                train_one_epoch(model, optimizer, criterion, train_loader, model_id=i+1, epoch_num=epoch, log_every=log_every_batches)\n",
        "\n",
        "        scores = [evaluate_model(m, val_loader) for m in population]\n",
        "        sorted_indices = np.argsort(scores)[::-1]\n",
        "\n",
        "        if scores[sorted_indices[0]] > best_score:\n",
        "            best_score = scores[sorted_indices[0]]\n",
        "            best_model = population[sorted_indices[0]]\n",
        "            best_optimizer = optimizers[sorted_indices[0]]\n",
        "            print(f\"  ðŸŽ‰ New best model with accuracy: {best_score:.4f}\")\n",
        "\n",
        "        survivors = max(1, int(len(population) * survival_rate))\n",
        "        population = [population[i] for i in sorted_indices[:survivors]]\n",
        "        optimizers = [optimizers[i] for i in sorted_indices[:survivors]]\n",
        "\n",
        "        if best_model not in population:\n",
        "            population.append(best_model)\n",
        "            optimizers.append(best_optimizer)\n",
        "            print(\"  ðŸ”„ Best model preserved with elitism\")\n",
        "\n",
        "        print(f\"  âœ… Best Acc This Gen: {scores[sorted_indices[0]]:.4f} | Worst: {scores[sorted_indices[-1]]:.4f}\")\n",
        "\n",
        "    torch.save(best_model.state_dict(), \"best_omniglot_cnn_model.pth\")\n",
        "    return best_model\n",
        "\n",
        "# ====== Run Training ======\n",
        "best_model = evolution_training_until_one(\n",
        "    population_size=1000,\n",
        "    survival_rate=0.6,\n",
        "    epochs_per_gen=10,\n",
        "    log_every_batches=100\n",
        ")\n",
        "\n",
        "# ====== Final Evaluation ======\n",
        "test_accuracy = evaluate_model(best_model, test_loader)\n",
        "print(f\"\\nðŸŽ¯ Final test accuracy on Omniglot: {test_accuracy * 100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import Omniglot\n",
        "import torchvision.transforms as transforms\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Define device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Resize transform: resize to 28x28 + ToTensor()\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((28, 28)),  # Resize images to 28x28\n",
        "    transforms.ToTensor(),        # Convert PIL image to tensor and scale to [0,1]\n",
        "])\n",
        "\n",
        "# Load Omniglot dataset (background=True for training, False for testing)\n",
        "train_dataset = Omniglot(root='./data', background=True, download=True, transform=transform)\n",
        "test_dataset = Omniglot(root='./data', background=False, download=True, transform=transform)\n",
        "\n",
        "# Combine train and test for one dataset\n",
        "full_data = train_dataset + test_dataset\n",
        "\n",
        "# Extract data and labels into numpy arrays\n",
        "X = []\n",
        "y = []\n",
        "for img, label in full_data:\n",
        "    X.append(img.numpy())  # Keep as image tensor (1, 28, 28)\n",
        "    y.append(label)\n",
        "\n",
        "X = np.stack(X)\n",
        "y = np.array(y)\n",
        "\n",
        "# Limit to first 50 classes to keep problem manageable\n",
        "max_classes = 50\n",
        "mask = y < max_classes\n",
        "X = X[mask]\n",
        "y = y[mask]\n",
        "\n",
        "# Encode labels 0..49\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "# Train/val/test split: 70% train, 15% val, 15% test\n",
        "X_trainval, X_test, y_trainval, y_test = train_test_split(\n",
        "    X, y_encoded, test_size=0.15, random_state=42, stratify=y_encoded\n",
        ")\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_trainval, y_trainval, test_size=0.1765, random_state=42, stratify=y_trainval\n",
        ")\n",
        "\n",
        "# Convert to tensors\n",
        "X_train_t = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_t = torch.tensor(y_train, dtype=torch.long)\n",
        "X_val_t = torch.tensor(X_val, dtype=torch.float32)\n",
        "y_val_t = torch.tensor(y_val, dtype=torch.long)\n",
        "X_test_t = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test_t = torch.tensor(y_test, dtype=torch.long)\n",
        "\n",
        "# Create dataloaders\n",
        "batch_size = 64\n",
        "train_loader = DataLoader(torch.utils.data.TensorDataset(X_train_t, y_train_t), batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(torch.utils.data.TensorDataset(X_val_t, y_val_t), batch_size=batch_size)\n",
        "test_loader = DataLoader(torch.utils.data.TensorDataset(X_test_t, y_test_t), batch_size=batch_size)\n",
        "\n",
        "# ====== Define CNN Model ======\n",
        "class OmniglotCNN(nn.Module):\n",
        "    def __init__(self, num_classes=max_classes):\n",
        "        super(OmniglotCNN, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, kernel_size=3, padding=1),  # input channel=1 (grayscale)\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),  # 28x28 -> 14x14\n",
        "            nn.Dropout(0.25),\n",
        "\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),  # 14x14 -> 7x7\n",
        "            nn.Dropout(0.25)\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(64 * 7 * 7, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(128, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "# Evaluation function\n",
        "def evaluate_model(model, dataloader):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_targets = []\n",
        "    with torch.no_grad():\n",
        "        for xb, yb in dataloader:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            logits = model(xb)  # no flatten before CNN\n",
        "            preds = torch.argmax(logits, dim=1)\n",
        "            all_preds.append(preds.cpu().numpy())\n",
        "            all_targets.append(yb.cpu().numpy())\n",
        "    all_preds = np.concatenate(all_preds)\n",
        "    all_targets = np.concatenate(all_targets)\n",
        "    acc = accuracy_score(all_targets, all_preds)\n",
        "    return acc\n",
        "\n",
        "# Training function for one epoch\n",
        "def train_one_epoch(model, optimizer, criterion, dataloader):\n",
        "    model.train()\n",
        "    running_loss = 0\n",
        "    for xb, yb in dataloader:\n",
        "        xb, yb = xb.to(device), yb.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(xb)\n",
        "        loss = criterion(logits, yb)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item() * xb.size(0)\n",
        "    return running_loss / len(dataloader.dataset)\n",
        "\n",
        "# Instantiate model, loss, optimizer\n",
        "model = OmniglotCNN().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Optional: Enable cudnn benchmark for performance if CUDA\n",
        "if device.type == 'cuda':\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 150\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss = train_one_epoch(model, optimizer, criterion, train_loader)\n",
        "    if (epoch + 1) % 5 == 0 or epoch == 0:\n",
        "        val_acc = evaluate_model(model, val_loader)\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs} - Train Loss: {train_loss:.4f} - Val Accuracy: {val_acc:.4f}\")\n",
        "\n",
        "# Final evaluation on test set\n",
        "test_acc = evaluate_model(model, test_loader) * 100\n",
        "print(f\"\\nFinal Test Accuracy: {test_acc:.4f} %\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ruCJnTS0q6GI",
        "outputId": "7527dbc6-dacb-414f-ea36-26e5ba88f6c3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9.46M/9.46M [00:00<00:00, 311MB/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6.46M/6.46M [00:00<00:00, 366MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150 - Train Loss: 3.9315 - Val Accuracy: 0.0199\n",
            "Epoch 5/150 - Train Loss: 3.9133 - Val Accuracy: 0.0199\n",
            "Epoch 10/150 - Train Loss: 3.8744 - Val Accuracy: 0.0565\n",
            "Epoch 15/150 - Train Loss: 3.4445 - Val Accuracy: 0.1329\n",
            "Epoch 20/150 - Train Loss: 2.9937 - Val Accuracy: 0.2027\n",
            "Epoch 25/150 - Train Loss: 2.6437 - Val Accuracy: 0.3223\n",
            "Epoch 30/150 - Train Loss: 2.3432 - Val Accuracy: 0.4086\n",
            "Epoch 35/150 - Train Loss: 2.1276 - Val Accuracy: 0.4618\n",
            "Epoch 40/150 - Train Loss: 1.9724 - Val Accuracy: 0.5050\n",
            "Epoch 45/150 - Train Loss: 1.8483 - Val Accuracy: 0.5216\n",
            "Epoch 50/150 - Train Loss: 1.7862 - Val Accuracy: 0.5415\n",
            "Epoch 55/150 - Train Loss: 1.7716 - Val Accuracy: 0.5482\n",
            "Epoch 60/150 - Train Loss: 1.6440 - Val Accuracy: 0.5382\n",
            "Epoch 65/150 - Train Loss: 1.6386 - Val Accuracy: 0.5714\n",
            "Epoch 70/150 - Train Loss: 1.5438 - Val Accuracy: 0.5880\n",
            "Epoch 75/150 - Train Loss: 1.4940 - Val Accuracy: 0.5880\n",
            "Epoch 80/150 - Train Loss: 1.4957 - Val Accuracy: 0.6146\n",
            "Epoch 85/150 - Train Loss: 1.3926 - Val Accuracy: 0.6179\n",
            "Epoch 90/150 - Train Loss: 1.3645 - Val Accuracy: 0.6179\n",
            "Epoch 95/150 - Train Loss: 1.3186 - Val Accuracy: 0.6113\n",
            "Epoch 100/150 - Train Loss: 1.3295 - Val Accuracy: 0.6080\n",
            "Epoch 105/150 - Train Loss: 1.3323 - Val Accuracy: 0.6146\n",
            "Epoch 110/150 - Train Loss: 1.3195 - Val Accuracy: 0.6213\n",
            "Epoch 115/150 - Train Loss: 1.2036 - Val Accuracy: 0.6379\n",
            "Epoch 120/150 - Train Loss: 1.2141 - Val Accuracy: 0.6545\n",
            "Epoch 125/150 - Train Loss: 1.1842 - Val Accuracy: 0.6412\n",
            "Epoch 130/150 - Train Loss: 1.2327 - Val Accuracy: 0.6512\n",
            "Epoch 135/150 - Train Loss: 1.1521 - Val Accuracy: 0.6279\n",
            "Epoch 140/150 - Train Loss: 1.1872 - Val Accuracy: 0.6445\n",
            "Epoch 145/150 - Train Loss: 1.1181 - Val Accuracy: 0.6279\n",
            "Epoch 150/150 - Train Loss: 1.1168 - Val Accuracy: 0.6611\n",
            "\n",
            "Final Test Accuracy: 67.3333 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "def generations_to_one(pop_size, survival_rate):\n",
        "    # Calculate how many generations until population shrinks to 1 or less\n",
        "    return 1 + math.ceil(math.log(1 / pop_size) / math.log(survival_rate))\n",
        "\n",
        "def total_epochs_final_model(pop_size, survival_rate, epochs_per_gen):\n",
        "    G = generations_to_one(pop_size, survival_rate)\n",
        "    total = G * epochs_per_gen\n",
        "    return total, G\n",
        "\n",
        "# Example usage:\n",
        "pop_size = 1000\n",
        "survival_rate = 0.6\n",
        "epochs_per_gen = 10  # for example\n",
        "\n",
        "\n",
        "total, generations = total_epochs_final_model(pop_size, survival_rate, epochs_per_gen)\n",
        "print(f\"Generations: {generations}, Total epochs for final model: {total}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZPsHZfON_Yl",
        "outputId": "c81fe2ac-7927-468f-dccc-841cb79d9619"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generations: 15, Total epochs for final model: 150\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "fXlRiq_PinhH"
      },
      "execution_count": 62,
      "outputs": []
    }
  ]
}