{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "authorship_tag": "ABX9TyMwZPM0G/2MSBZ30gqMrdIV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nikalitt1/Clementine-Agriculture/blob/main/Juniper_Setup/clementine_ag_Juniper_setup.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![clementine_logo_noback_small.PNG](data:image/png;base64,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)\n",
        "\n",
        "# Clementine Agriculture Tutorial: Training, deployment and setup of scripts for the Juniper and other modules\n",
        "\n",
        "Welcome!\n",
        "\n",
        "This tutorial will include:\n",
        "* Setting up Jetson Orin Nano for deploymeny in Clementine Ag products\n",
        "*Scripts for product operation, training, and datacollection\n"
      ],
      "metadata": {
        "id": "TzIwCOw6cl5r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, run the following commands on the Jetson orin nano after initial boot into Jetpack 6.2 in order have all the packages run properly. These setup commands can be found in the following links as well:\n",
        "\n",
        "* https://docs.ultralytics.com/guides/nvidia-jetson/#install-ultralytics-package\n",
        "* https://docs.ultralytics.com/modes/train/#apple-silicon-mps-training\n",
        "* https://www.youtube.com/watch?v=7P6I2jeJNYo  (CH340 Kernel build)\n",
        "* https://www.youtube.com/watch?v=OYrSADrtSag&t=177s   (NoMachine setup)\n",
        "* https://www.stereolabs.com/en-ca/developers/drivers  (ZED Link Mono install)\n"
      ],
      "metadata": {
        "id": "afqB6KCVc6sb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: Initial Jetson Orin Nano setup"
      ],
      "metadata": {
        "id": "n69TS7qQhmZn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once the Jetson Orin Nano is flashed with Jetpack 6.2, use the following commands to set up the ZED X Mini camera."
      ],
      "metadata": {
        "id": "SHjXsZbpZVRm"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PMZ-xjSLfAbO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This next step is to start a virtual environment on the Jetson ON, but because this computer will not be used as a general device and is only running the scripts for the Juniper, its not mandatory."
      ],
      "metadata": {
        "id": "LGeSwPqtfMBf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sudo apt install python3-venv\n",
        "python3 -m venv depthai\n",
        "source depthai/bin/activate"
      ],
      "metadata": {
        "id": "tB5NsN60fCcr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Clone github repository\n",
        "git clone https://github.com/luxonis/depthai-python.git\n",
        "cd depthai-python\n",
        "python3 examples/install_requirements.py"
      ],
      "metadata": {
        "id": "43y641egfFUd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "echo \"export OPENBLAS_CORETYPE=ARMV8\" >> ~/.bashrc"
      ],
      "metadata": {
        "id": "J5neOPOBff_w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once you have copy and pasted each of these commands into a freshly botted Jetson ON running Jetpack 6.2, the OAK D Lite camera should work when connected to the Jetson ON via USB port.\n",
        "\n",
        "The next commands should also be run on the Jetson ON, they are the setup commands so that Ultralytics YOLO models can run on the Jetson ON properly."
      ],
      "metadata": {
        "id": "diJH3S1SfkB9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sudo apt update\n",
        "sudo apt install python3-pip -y\n",
        "pip install -U pip"
      ],
      "metadata": {
        "id": "N9vZtxuagH1x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install ultralytics"
      ],
      "metadata": {
        "id": "fYh1ppgJgcpp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sudo reboot"
      ],
      "metadata": {
        "id": "CkmIOYiAggbc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install https://github.com/ultralytics/assets/releases/download/v0.0.0/torch-2.5.0a0+872d972e41.nv24.08-cp310-cp310-linux_aarch64.whl\n",
        "pip install https://github.com/ultralytics/assets/releases/download/v0.0.0/torchvision-0.20.0a0+afc54f7-cp310-cp310-linux_aarch64.whl"
      ],
      "metadata": {
        "id": "33cd-Ak2gjNX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/arm64/cuda-keyring_1.1-1_all.deb\n",
        "sudo dpkg -i cuda-keyring_1.1-1_all.deb\n",
        "sudo apt-get update\n",
        "sudo apt-get -y install libcusparselt0 libcusparselt-dev"
      ],
      "metadata": {
        "id": "Dhuzs-vqgm0m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install https://github.com/ultralytics/assets/releases/download/v0.0.0/onnxruntime_gpu-1.20.0-cp310-cp310-linux_aarch64.whl"
      ],
      "metadata": {
        "id": "j5UA-DCJgpoy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install numpy==1.23.5"
      ],
      "metadata": {
        "id": "0IOBfKIQgszv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since numpy will be version 1.23.5 on the Jetson ON, you also need to install that version in this colab to ensure when any training scripts are run in this colab it will use the same version of numpy. If you do not do this the trained model will not work once you transfer it to the Jeton ON. Run the command below in this colab:"
      ],
      "metadata": {
        "id": "JgSRaCSugwhT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy==1.23.5"
      ],
      "metadata": {
        "id": "41OIb71lhFUn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba3c5705-a79e-4761-89ed-11773ad68255"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy==1.23.5 in /usr/local/lib/python3.11/dist-packages (1.23.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Step 2: Collecting Data for Object Detection"
      ],
      "metadata": {
        "id": "oc4FqfhgLg_I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Connect an ZED X Mini camera to this computer via a CSI CAble, run the below script and collect as much high quality video feed of the objecdts you want to identify:"
      ],
      "metadata": {
        "id": "DgZNbk6sLsJm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pyzed.sl as sl\n",
        "import cv2\n",
        "import signal\n",
        "\n",
        "stop = False\n",
        "\n",
        "def signal_handler(sig, frame):\n",
        "    global stop\n",
        "    stop = True\n",
        "\n",
        "signal.signal(signal.SIGINT, signal_handler)\n",
        "\n",
        "def main():\n",
        "    # Create ZED Camera object\n",
        "    zed = sl.Camera()\n",
        "\n",
        "    # Init parameters\n",
        "    init_params = sl.InitParameters()\n",
        "    init_params.camera_resolution = sl.RESOLUTION.HD1080  # or sl.RESOLUTION.VGA for smaller\n",
        "    init_params.camera_fps = 30\n",
        "\n",
        "    # Open camera\n",
        "    if zed.open(init_params) != sl.ERROR_CODE.SUCCESS:\n",
        "        print(\"Failed to open ZED camera\")\n",
        "        return\n",
        "\n",
        "    runtime_params = sl.RuntimeParameters()\n",
        "\n",
        "    # Set frame size for VideoWriter (must match camera_resolution)\n",
        "    frame_width = 1920\n",
        "    frame_height = 1080\n",
        "\n",
        "    output_file = \"belt_training20.avi\"\n",
        "    fourcc = cv2.VideoWriter_fourcc(*\"XVID\")  # Use XVID codec\n",
        "\n",
        "    out = cv2.VideoWriter(output_file, fourcc, 60, (frame_width, frame_height))\n",
        "\n",
        "    if not out.isOpened():\n",
        "        print(\"Failed to open VideoWriter with XVID codec.\")\n",
        "        zed.close()\n",
        "        return\n",
        "\n",
        "    image = sl.Mat()\n",
        "\n",
        "    print(\"Recording started. Press Ctrl+C or 'q' to stop.\")\n",
        "\n",
        "    while not stop:\n",
        "        if zed.grab(runtime_params) == sl.ERROR_CODE.SUCCESS:\n",
        "            zed.retrieve_image(image, sl.VIEW.LEFT)\n",
        "            frame = image.get_data()\n",
        "\n",
        "            # Convert BGRA to BGR (drop alpha)\n",
        "            frame_bgr = cv2.cvtColor(frame, cv2.COLOR_BGRA2BGR)\n",
        "\n",
        "            # Resize if needed (should already match, but just in case)\n",
        "            if (frame_bgr.shape[1], frame_bgr.shape[0]) != (frame_width, frame_height):\n",
        "                frame_resized = cv2.resize(frame_bgr, (frame_width, frame_height))\n",
        "            else:\n",
        "                frame_resized = frame_bgr\n",
        "\n",
        "            out.write(frame_resized)\n",
        "\n",
        "            preview = cv2.resize(frame_bgr, (640, 360))\n",
        "            cv2.imshow(\"ZED X Mini Preview\", preview)\n",
        "\n",
        "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "                break\n",
        "        else:\n",
        "            print(\"Grab failed\")\n",
        "\n",
        "    print(\"Stopping recording...\")\n",
        "    out.release()\n",
        "    zed.close()\n",
        "    cv2.destroyAllWindows()\n",
        "    print(f\"Video saved to {output_file}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "b2ifvGjwL2UN",
        "outputId": "082522c7-103c-4ac2-a507-f59d7d1950bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-a5e381080b58>:14: DeprecationWarning: RGB is deprecated, use CAM_A or address camera by name instead.\n",
            "  cam_rgb.setBoardSocket(dai.CameraBoardSocket.RGB)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Cannot find any device with given deviceInfo",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-a5e381080b58>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# Connect to the device and start the pipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mdai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Connected to OAK-D Lite. Press 'q' to quit.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Cannot find any device with given deviceInfo"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3: Training Ultralytics YOLO11n Model"
      ],
      "metadata": {
        "id": "MKcechtjhjHL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The annotating and dataset preparation can be done for any model in Roboflow, make sure to export the dataset as a zip file in \"YOLO V5 Pytorch format\". From here on it will be assumed the dataset is already prepared and saved."
      ],
      "metadata": {
        "id": "x6QX4RJnh5sb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Upload the dataset zip file from roboflow in the side bar, then run the following commands to trin the yolo11n model. make sure to change the file names accordingly, and modify the data.yaml file to match the actual paths to the train, test, and validation paths."
      ],
      "metadata": {
        "id": "eupLTHgrjDBj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics"
      ],
      "metadata": {
        "id": "uSWYGGvvxNxl",
        "outputId": "db54680d-755b-477e-8a94-969a7e044863",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Using cached ultralytics-8.3.192-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.23.5)\n",
            "Collecting matplotlib>=3.3.0 (from ultralytics)\n",
            "  Downloading matplotlib-3.10.6-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\n",
            "Collecting opencv-python>=4.6.0 (from ultralytics)\n",
            "  Downloading opencv_python-4.12.0.88-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (19 kB)\n",
            "Collecting pillow>=7.1.2 (from ultralytics)\n",
            "  Downloading pillow-11.3.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (9.0 kB)\n",
            "Collecting pyyaml>=5.3.1 (from ultralytics)\n",
            "  Downloading PyYAML-6.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting requests>=2.23.0 (from ultralytics)\n",
            "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting scipy>=1.4.1 (from ultralytics)\n",
            "  Downloading scipy-1.15.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Collecting torch>=1.8.0 (from ultralytics)\n",
            "  Downloading torch-2.8.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (30 kB)\n",
            "Collecting torchvision>=0.9.0 (from ultralytics)\n",
            "  Downloading torchvision-0.23.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
            "Collecting psutil (from ultralytics)\n",
            "  Downloading psutil-7.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n",
            "Collecting py-cpuinfo (from ultralytics)\n",
            "  Downloading py_cpuinfo-9.0.0-py3-none-any.whl.metadata (794 bytes)\n",
            "Collecting polars (from ultralytics)\n",
            "  Downloading polars-1.33.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (15 kB)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Using cached ultralytics_thop-2.0.17-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting contourpy>=1.0.1 (from matplotlib>=3.3.0->ultralytics)\n",
            "  Downloading contourpy-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
            "Collecting cycler>=0.10 (from matplotlib>=3.3.0->ultralytics)\n",
            "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting fonttools>=4.22.0 (from matplotlib>=3.3.0->ultralytics)\n",
            "  Downloading fonttools-4.59.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (109 kB)\n",
            "Collecting kiwisolver>=1.3.1 (from matplotlib>=3.3.0->ultralytics)\n",
            "  Downloading kiwisolver-1.4.9-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.3 kB)\n",
            "Collecting packaging>=20.0 (from matplotlib>=3.3.0->ultralytics)\n",
            "  Downloading packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.4.7)\n",
            "Collecting python-dateutil>=2.7 (from matplotlib>=3.3.0->ultralytics)\n",
            "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting numpy>=1.23.0 (from ultralytics)\n",
            "  Downloading numpy-2.2.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Collecting charset_normalizer<4,>=2 (from requests>=2.23.0->ultralytics)\n",
            "  Downloading charset_normalizer-3.4.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (36 kB)\n",
            "Collecting idna<4,>=2.5 (from requests>=2.23.0->ultralytics)\n",
            "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests>=2.23.0->ultralytics)\n",
            "  Downloading urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting certifi>=2017.4.17 (from requests>=2.23.0->ultralytics)\n",
            "  Downloading certifi-2025.8.3-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting filelock (from torch>=1.8.0->ultralytics)\n",
            "  Downloading filelock-3.19.1-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting typing-extensions>=4.10.0 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting sympy>=1.13.3 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting networkx (from torch>=1.8.0->ultralytics)\n",
            "  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting jinja2 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting fsspec (from torch>=1.8.0->ultralytics)\n",
            "  Downloading fsspec-2025.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.8.90 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.8.90 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.10.2.21 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-cublas-cu12==12.8.4.1 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cufft-cu12==11.3.3.83 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.9.90 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.7.3.90 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.5.8.93 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-cusparselt-cu12==0.7.1 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
            "Collecting nvidia-nccl-cu12==2.27.3 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_nccl_cu12-2.27.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.8.90 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.8.93 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cufile-cu12==1.13.1.3 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==3.4.0 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading triton-3.4.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.10/dist-packages (from triton==3.4.0->torch>=1.8.0->ultralytics) (80.9.0)\n",
            "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch>=1.8.0->ultralytics)\n",
            "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/lib/python3/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.0.1)\n",
            "Using cached ultralytics-8.3.192-py3-none-any.whl (1.1 MB)\n",
            "Downloading matplotlib-3.10.6-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m113.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading contourpy-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (325 kB)\n",
            "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
            "Downloading fonttools-4.59.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (4.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m125.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kiwisolver-1.4.9-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m83.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencv_python-4.12.0.88-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (67.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 MB\u001b[0m \u001b[31m132.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-2.2.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m158.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading packaging-25.0-py3-none-any.whl (66 kB)\n",
            "Downloading pillow-11.3.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m138.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
            "Downloading PyYAML-6.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (751 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m751.2/751.2 kB\u001b[0m \u001b[31m40.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "Downloading charset_normalizer-3.4.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (152 kB)\n",
            "Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
            "Downloading urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
            "Downloading certifi-2025.8.3-py3-none-any.whl (161 kB)\n",
            "Downloading scipy-1.15.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.7/37.7 MB\u001b[0m \u001b[31m138.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.8.0-cp310-cp310-manylinux_2_28_x86_64.whl (888.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m888.0/888.0 MB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m  \u001b[33m0:00:11\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m37.3 MB/s\u001b[0m  \u001b[33m0:00:08\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m157.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m123.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m954.8/954.8 kB\u001b[0m \u001b[31m58.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl (706.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m706.8/706.8 MB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m  \u001b[33m0:00:09\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m62.2 MB/s\u001b[0m  \u001b[33m0:00:03\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m71.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m121.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m59.2 MB/s\u001b[0m  \u001b[33m0:00:04\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.2/288.2 MB\u001b[0m \u001b[31m60.0 MB/s\u001b[0m  \u001b[33m0:00:04\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl (287.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.2/287.2 MB\u001b[0m \u001b[31m56.2 MB/s\u001b[0m  \u001b[33m0:00:04\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.27.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.4/322.4 MB\u001b[0m \u001b[31m59.3 MB/s\u001b[0m  \u001b[33m0:00:04\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m131.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
            "Downloading triton-3.4.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (155.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.4/155.4 MB\u001b[0m \u001b[31m63.9 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0m\n",
            "\u001b[?25hDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m143.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchvision-0.23.0-cp310-cp310-manylinux_2_28_x86_64.whl (8.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m157.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
            "Using cached ultralytics_thop-2.0.17-py3-none-any.whl (28 kB)\n",
            "Downloading filelock-3.19.1-py3-none-any.whl (15 kB)\n",
            "Downloading fsspec-2025.9.0-py3-none-any.whl (199 kB)\n",
            "Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
            "Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m43.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading polars-1.33.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (39.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m124.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading psutil-7.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (277 kB)\n",
            "Downloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: py-cpuinfo, nvidia-cusparselt-cu12, mpmath, urllib3, typing-extensions, triton, sympy, pyyaml, python-dateutil, psutil, polars, pillow, packaging, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, kiwisolver, jinja2, idna, fsspec, fonttools, filelock, cycler, charset_normalizer, certifi, scipy, requests, opencv-python, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, contourpy, nvidia-cusolver-cu12, matplotlib, torch, ultralytics-thop, torchvision, ultralytics\n",
            "\u001b[2K  Attempting uninstall: numpy\n",
            "\u001b[2K    Found existing installation: numpy 1.23.5\n",
            "\u001b[2K    Uninstalling numpy-1.23.5:\n",
            "\u001b[2K      Successfully uninstalled numpy-1.23.5\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46/46\u001b[0m [ultralytics]\n",
            "\u001b[1A\u001b[2KSuccessfully installed certifi-2025.8.3 charset_normalizer-3.4.3 contourpy-1.3.2 cycler-0.12.1 filelock-3.19.1 fonttools-4.59.2 fsspec-2025.9.0 idna-3.10 jinja2-3.1.6 kiwisolver-1.4.9 matplotlib-3.10.6 mpmath-1.3.0 networkx-3.4.2 numpy-2.2.6 nvidia-cublas-cu12-12.8.4.1 nvidia-cuda-cupti-cu12-12.8.90 nvidia-cuda-nvrtc-cu12-12.8.93 nvidia-cuda-runtime-cu12-12.8.90 nvidia-cudnn-cu12-9.10.2.21 nvidia-cufft-cu12-11.3.3.83 nvidia-cufile-cu12-1.13.1.3 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-cusparselt-cu12-0.7.1 nvidia-nccl-cu12-2.27.3 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvtx-cu12-12.8.90 opencv-python-4.12.0.88 packaging-25.0 pillow-11.3.0 polars-1.33.0 psutil-7.0.0 py-cpuinfo-9.0.0 python-dateutil-2.9.0.post0 pyyaml-6.0.2 requests-2.32.5 scipy-1.15.3 sympy-1.14.0 torch-2.8.0 torchvision-0.23.0 triton-3.4.0 typing-extensions-4.15.0 ultralytics-8.3.192 ultralytics-thop-2.0.17 urllib3-2.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get update -y"
      ],
      "metadata": {
        "id": "5csHburhjQzR",
        "outputId": "538c188a-d187-43be-82c4-9604ea9b1ce1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 https://cli.github.com/packages stable InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com (185.125.190.81)] [Waiting for headers] [C\r                                                                               \rGet:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "\r0% [Connecting to archive.ubuntu.com (185.125.190.81)] [Waiting for headers] [C\r                                                                               \rGet:3 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Get:4 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,961 kB]\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:7 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:9 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,232 kB]\n",
            "Get:10 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,310 kB]\n",
            "Hit:11 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:12 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:13 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [5,374 kB]\n",
            "Get:16 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,790 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,623 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,579 kB]\n",
            "Fetched 28.3 MB in 2s (11.6 MB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install python3.10 python3.10-distutils -y"
      ],
      "metadata": {
        "id": "4ZNBZaCVjQn7",
        "outputId": "f6053261-f4fa-40e5-c6dc-ad25af9e61cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "Note, selecting 'python3-distutils' instead of 'python3.10-distutils'\n",
            "python3-distutils is already the newest version (3.10.8-1~22.04).\n",
            "python3-distutils set to manually installed.\n",
            "python3.10 is already the newest version (3.10.12-1~22.04.11).\n",
            "python3.10 set to manually installed.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 36 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py"
      ],
      "metadata": {
        "id": "9Zl_yEXSjQkI",
        "outputId": "15665a4f-073c-42f2-eb59-e88142dc0d79",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 2098k  100 2098k    0     0  7314k      0 --:--:-- --:--:-- --:--:-- 7336k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3.10 get-pip.py"
      ],
      "metadata": {
        "id": "9mUsARs8jQea",
        "outputId": "e1d9f601-22b2-441f-e483-876c797caba5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pip\n",
            "  Downloading pip-25.2-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting setuptools\n",
            "  Downloading setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting wheel\n",
            "  Downloading wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Downloading pip-25.2-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wheel-0.45.1-py3-none-any.whl (72 kB)\n",
            "Installing collected packages: wheel, setuptools, pip\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/3\u001b[0m [pip]\n",
            "\u001b[1A\u001b[2KSuccessfully installed pip-25.2 setuptools-80.9.0 wheel-0.45.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3.10 -m pip install numpy==1.23.5"
      ],
      "metadata": {
        "id": "_cahWQaVjQPl",
        "outputId": "8e4f7a7b-75c5-4bfb-839a-793dbf7b8bb4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy==1.23.5\n",
            "  Using cached numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n",
            "Using cached numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "Installing collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.2.6\n",
            "    Uninstalling numpy-2.2.6:\n",
            "      Successfully uninstalled numpy-2.2.6\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.23.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.23.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/"
      ],
      "metadata": {
        "id": "QhfsBjSfxUeK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q /content/roboflow_dataset.zip -d /content/dataset/"
      ],
      "metadata": {
        "id": "hT1Yr_IOnepJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!yolo detect train data=data.yaml model=yolo11n.yaml epochs=100 imgsz=640"
      ],
      "metadata": {
        "id": "4s9BFLFIjl1J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "once run, the model weights can be found in the following file path in the side bar: /yolov5/runs/train/exp/weights/best.pt\n",
        "\n",
        "you can now send the model weights (best.pt) to the Jetson ON."
      ],
      "metadata": {
        "id": "L5ovZ-KCoRRA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now on the Jetson ON, you cannot directly run the best.pt file, you first need to convert it to a .engine file with the following command, make sure to run this command on the Jetson ON!"
      ],
      "metadata": {
        "id": "iAyPQbbzoraP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "yolo export model=yolo11n.pt format=engine # creates 'yolo11n.engine'"
      ],
      "metadata": {
        "id": "qXYkq93lo1G4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Great, now the object detection setup is done, now its time to train two random forest models to get the W.A.S.P arms to aim accurately at the targets identified by the YOLO11n model."
      ],
      "metadata": {
        "id": "5Uldq807pAwN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Step 4: Training Random Forest Aiming Model"
      ],
      "metadata": {
        "id": "0ibMl9ejpM8r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random forests are a type of decision tree which can be thought of as a precursor to neural nets. They are better for maping pixel and depth coordinates to servo motor agles then traditional nurel nets because they are more robust when new data it has not been trainined on is presented. In the future the W.A.S.P will be training using reinforced learning methods in order to make sure it aims accurately and properly in a number of different scenarios. Unfortunately, Random forests cannot be fine tuned in real time like reinforced learning models. but for ealy models random forests are more then enough to aim accurately in most settings. The code below should be ran on the Jetson ON, it is used to collect data for the random forests model, remember to change the pin numbers for each arm:"
      ],
      "metadata": {
        "id": "0svO5lmJpToF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import depthai as dai\n",
        "import time\n",
        "import threading\n",
        "import numpy as np\n",
        "import csv\n",
        "from smbus2 import SMBus\n",
        "import math  # For atan2\n",
        "\n",
        "# PCA9685 Constants\n",
        "PCA9685_ADDRESS = 0x40\n",
        "MODE1 = 0x00\n",
        "MODE2 = 0x01\n",
        "LED0_ON_L = 0x06\n",
        "LED0_ON_H = 0x07\n",
        "LED0_OFF_L = 0x08\n",
        "LED0_OFF_H = 0x09\n",
        "\n",
        "bus = SMBus(7)\n",
        "\n",
        "# Initialize PCA9685\n",
        "def init_pca9685():\n",
        "    bus.write_byte_data(PCA9685_ADDRESS, MODE1, 0x00)\n",
        "    bus.write_byte_data(PCA9685_ADDRESS, MODE2, 0x04)\n",
        "    time.sleep(0.1)\n",
        "\n",
        "# Set PWM for servo motors\n",
        "def set_pwm(channel, pulse_width):\n",
        "    on_time = 0\n",
        "    off_time = int(pulse_width)\n",
        "    bus.write_byte_data(PCA9685_ADDRESS, LED0_ON_L + 4 * channel, on_time & 0xFF)\n",
        "    bus.write_byte_data(PCA9685_ADDRESS, LED0_ON_H + 4 * channel, (on_time >> 8) & 0xFF)\n",
        "    bus.write_byte_data(PCA9685_ADDRESS, LED0_OFF_L + 4 * channel, off_time & 0xFF)\n",
        "    bus.write_byte_data(PCA9685_ADDRESS, LED0_OFF_H + 4 * channel, (off_time >> 8) & 0xFF)\n",
        "\n",
        "def angle_to_pulse_width(angle, min_us=500, max_us=2500):\n",
        "    return int((angle / 180.0) * (max_us - min_us) + min_us)\n",
        "\n",
        "# Control the laser diode\n",
        "def control_diode(on=True):\n",
        "    pulse_width = int((0.3 / 100.0) * 4095)\n",
        "    set_pwm(13, pulse_width if on else 0)\n",
        "\n",
        "# Save data to CSV\n",
        "def save_to_csv(angle_0, angle_1, depth, center_x, center_y, tilt_x, tilt_y):\n",
        "    with open('mlp_training_data_long.csv', mode='a', newline='') as file:\n",
        "        writer = csv.writer(file)\n",
        "        writer.writerow([angle_0, angle_1, depth, center_x, center_y, tilt_x, tilt_y])\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def generate_zigzag_path(x_range, y_range, x_step, y_step, start_corner='top-left', zigzag_axis='horizontal'):\n",
        "    path = []\n",
        "    x_min, x_max = x_range\n",
        "    y_min, y_max = y_range\n",
        "\n",
        "    # Generate the axis ranges using numpy to support floats\n",
        "    x_forward = np.arange(x_min, x_max + x_step, x_step)\n",
        "    x_backward = x_forward[::-1]\n",
        "    y_forward = np.arange(y_min, y_max + y_step, y_step)\n",
        "    y_backward = y_forward[::-1]\n",
        "\n",
        "    corners = {\n",
        "        'top-left':     (x_forward,  y_forward),\n",
        "        'top-right':    (x_backward, y_forward),\n",
        "        'bottom-left':  (x_forward,  y_backward),\n",
        "        'bottom-right': (x_backward, y_backward)\n",
        "    }\n",
        "\n",
        "    if start_corner not in corners:\n",
        "        raise ValueError(f\"Invalid start_corner '{start_corner}'. Choose from: {list(corners.keys())}\")\n",
        "    if zigzag_axis not in ['horizontal', 'vertical']:\n",
        "        raise ValueError(\"zigzag_axis must be 'horizontal' or 'vertical'\")\n",
        "\n",
        "    x_order, y_order = corners[start_corner]\n",
        "\n",
        "    if zigzag_axis == 'horizontal':\n",
        "        for i, y in enumerate(y_order):\n",
        "            x_values = x_order if i % 2 == 0 else x_order[::-1]\n",
        "            for x in x_values:\n",
        "                path.append((round(x, 6), round(y, 6)))\n",
        "    else:  # vertical\n",
        "        for i, x in enumerate(x_order):\n",
        "            y_values = y_order if i % 2 == 0 else y_order[::-1]\n",
        "            for y in y_values:\n",
        "                path.append((round(x, 6), round(y, 6)))\n",
        "\n",
        "    return path\n",
        "\n",
        "\n",
        "\n",
        "# Calculate tilt from accelerometer data\n",
        "def calculate_tilt(accel_x, accel_y, accel_z):\n",
        "    tilt_x = math.atan2(accel_x, math.sqrt(accel_y**2 + accel_z**2))  # Pitch\n",
        "    tilt_y = math.atan2(accel_y, math.sqrt(accel_x**2 + accel_z**2))  # Roll\n",
        "    return math.degrees(tilt_x), math.degrees(tilt_y)  # Convert radians to degrees\n",
        "\n",
        "def move_servos(angle_list, video_queue, depth_queue, imu_queue, stop_event):\n",
        "    angle_index = 0\n",
        "    direction = 1  # 1 for forward, -1 for reverse\n",
        "\n",
        "    while not stop_event.is_set():\n",
        "        angle_x, angle_y = angle_list[angle_index]\n",
        "\n",
        "        # Capture frame and depth before moving the servos\n",
        "        frame_data = video_queue.get()\n",
        "        frame = frame_data.getCvFrame()\n",
        "\n",
        "        depth_data = depth_queue.get()\n",
        "        depth_frame = depth_data.getFrame()\n",
        "\n",
        "        imu_data = imu_queue.get()\n",
        "        imu_packets = imu_data.packets\n",
        "\n",
        "        tilt_x, tilt_y = 0, 0  # Default tilt values\n",
        "        for imu_packet in imu_packets:\n",
        "            gyro_data = imu_packet.gyroscope\n",
        "            accel_data = imu_packet.acceleroMeter  # Assuming accelerometer data is available\n",
        "\n",
        "            accel_x = accel_data.x\n",
        "            accel_y = accel_data.y\n",
        "            accel_z = accel_data.z\n",
        "\n",
        "            tilt_x, tilt_y = calculate_tilt(accel_x, accel_y, accel_z)\n",
        "\n",
        "            print(f\"Tilt Data - Pitch: {tilt_x:.2f}, Roll: {tilt_y:.2f}\")\n",
        "\n",
        "        # Process frame to find brightest spot\n",
        "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "        # Convert to grayscale and blur to reduce noise\n",
        "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "        blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "\n",
        "        # Apply a threshold to extract bright regions\n",
        "        _, thresh = cv2.threshold(blurred, 200, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "        # Find contours of bright areas\n",
        "        contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "        if contours:\n",
        "            # Find the largest bright area (by contour area)\n",
        "            largest_contour = max(contours, key=cv2.contourArea)\n",
        "\n",
        "            # Get the bounding box and center of the largest contour\n",
        "            x, y, w, h = cv2.boundingRect(largest_contour)\n",
        "            center_x = x + w // 2\n",
        "            center_y = y + h // 2\n",
        "\n",
        "            # Optionally draw the bounding box and center\n",
        "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 255), 2)\n",
        "            cv2.circle(frame, (center_x, center_y), 3, (0, 0, 255), -1)\n",
        "        else:\n",
        "            center_x, center_y = -1, -1  # No bright spot found\n",
        "\n",
        "\n",
        "        # Draw a bounding circle around the brightest spot\n",
        "        cv2.circle(frame, (center_x, center_y), 2, (0, 255, 0), 2)\n",
        "\n",
        "        depth_value = np.mean(depth_frame)\n",
        "\n",
        "        # Save the data\n",
        "        save_to_csv(angle_x, angle_y, round(depth_value), center_x, center_y, round(tilt_x, 2), round(tilt_y, 2))\n",
        "\n",
        "        # Move servos\n",
        "        set_pwm(15, angle_to_pulse_width(angle_x))\n",
        "        set_pwm(14, angle_to_pulse_width(angle_y))\n",
        "\n",
        "        control_diode(True)  # Turn on laser\n",
        "\n",
        "        # Update index with direction\n",
        "        angle_index += direction\n",
        "\n",
        "        # Reverse direction at ends\n",
        "        if angle_index == len(angle_list) - 1 or angle_index == 0:\n",
        "            direction *= -1\n",
        "\n",
        "        time.sleep(0.5)  # Adjust delay if needed\n",
        "\n",
        "\n",
        "# Setup depthai pipeline\n",
        "def setup_depthai_pipeline():\n",
        "    pipeline = dai.Pipeline()\n",
        "\n",
        "    # Color Camera\n",
        "    cam_rgb = pipeline.create(dai.node.ColorCamera)\n",
        "    cam_rgb.setPreviewSize(640, 360)\n",
        "    cam_rgb.setBoardSocket(dai.CameraBoardSocket.CAM_A)\n",
        "    cam_rgb.setResolution(dai.ColorCameraProperties.SensorResolution.THE_1080_P)\n",
        "    cam_rgb.setInterleaved(False)\n",
        "    cam_rgb.setColorOrder(dai.ColorCameraProperties.ColorOrder.BGR)\n",
        "    cam_rgb.setFps(35)\n",
        "\n",
        "    # Depth Camera\n",
        "    mono_left = pipeline.create(dai.node.MonoCamera)\n",
        "    mono_right = pipeline.create(dai.node.MonoCamera)\n",
        "    stereo = pipeline.create(dai.node.StereoDepth)\n",
        "\n",
        "    mono_left.setResolution(dai.MonoCameraProperties.SensorResolution.THE_480_P)\n",
        "    mono_right.setResolution(dai.MonoCameraProperties.SensorResolution.THE_480_P)\n",
        "    mono_left.setBoardSocket(dai.CameraBoardSocket.LEFT)\n",
        "    mono_right.setBoardSocket(dai.CameraBoardSocket.RIGHT)\n",
        "\n",
        "    stereo.setDefaultProfilePreset(dai.node.StereoDepth.PresetMode.HIGH_DENSITY)\n",
        "    stereo.setLeftRightCheck(True)\n",
        "    stereo.setDepthAlign(dai.CameraBoardSocket.CAM_A)\n",
        "    stereo.setSubpixel(True)\n",
        "\n",
        "    mono_left.out.link(stereo.left)\n",
        "    mono_right.out.link(stereo.right)\n",
        "\n",
        "    #IMU\n",
        "    imu = pipeline.create(dai.node.IMU)\n",
        "    imu.enableIMUSensor(dai.IMUSensor.GYROSCOPE_RAW, 100)\n",
        "    imu.enableIMUSensor(dai.IMUSensor.ACCELEROMETER_RAW, 100)\n",
        "    imu_queue = pipeline.create(dai.node.XLinkOut)\n",
        "    imu_queue.setStreamName(\"imu\")\n",
        "    imu.out.link(imu_queue.input)\n",
        "\n",
        "    # Output Streams\n",
        "    xout_rgb = pipeline.create(dai.node.XLinkOut)\n",
        "    xout_rgb.setStreamName(\"rgb\")\n",
        "    xout_depth = pipeline.create(dai.node.XLinkOut)\n",
        "    xout_depth.setStreamName(\"depth\")\n",
        "\n",
        "    cam_rgb.preview.link(xout_rgb.input)\n",
        "    stereo.depth.link(xout_depth.input)\n",
        "\n",
        "    return pipeline\n",
        "\n",
        "def main():\n",
        "    init_pca9685()\n",
        "\n",
        "    # Generate the angle list for flat its (25, 90) and (25, 59) for long its (20, 80) and (40, 75)\n",
        "    angle_list = generate_zigzag_path((25, 80), (40, 70), 1, 1, 'top-left', 'horizontal')\n",
        "\n",
        "    # Setup depthai pipeline\n",
        "    pipeline = setup_depthai_pipeline()\n",
        "\n",
        "    # Start depthai device\n",
        "    with dai.Device(pipeline) as device:\n",
        "        video_queue = device.getOutputQueue(name=\"rgb\", maxSize=4, blocking=False)\n",
        "        depth_queue = device.getOutputQueue(name=\"depth\", maxSize=4, blocking=False)\n",
        "        imu_queue = device.getOutputQueue(name=\"imu\", maxSize=4, blocking=False)\n",
        "        # Stop event to manage the thread\n",
        "        stop_event = threading.Event()\n",
        "\n",
        "        # Start the servo movement and data collection in a separate thread\n",
        "        threading.Thread(target=move_servos, args=(angle_list, video_queue, depth_queue, imu_queue, stop_event), daemon=True).start()\n",
        "\n",
        "        while True:\n",
        "            try:\n",
        "                frame_data = video_queue.get()\n",
        "                frame = frame_data.getCvFrame()\n",
        "\n",
        "                # Convert to grayscale and blur to reduce noise\n",
        "                gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "                blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "\n",
        "                # Apply a threshold to extract bright regions\n",
        "                _, thresh = cv2.threshold(blurred, 200, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "                # Find contours of bright areas\n",
        "                contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "                if contours:\n",
        "                    # Find the largest bright area (by contour area)\n",
        "                    largest_contour = max(contours, key=cv2.contourArea)\n",
        "\n",
        "                    # Get the bounding box and center of the largest contour\n",
        "                    x, y, w, h = cv2.boundingRect(largest_contour)\n",
        "                    center_x = x + w // 2\n",
        "                    center_y = y + h // 2\n",
        "\n",
        "                    # Draw the bounding box and center\n",
        "                    cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 255), 2)\n",
        "                    cv2.circle(frame, (center_x, center_y), 3, (0, 0, 255), -1)\n",
        "                else:\n",
        "                    center_x, center_y = -1, -1\n",
        "                    cv2.circle(frame, (center_x, center_y), 2, (0, 255, 0), 2)\n",
        "\n",
        "                # Display the current frame with circle\n",
        "                cv2.imshow(\"Detection\", frame)\n",
        "\n",
        "                if cv2.waitKey(1) == ord(\"q\"):\n",
        "                    stop_event.set()\n",
        "                    break\n",
        "\n",
        "            except KeyboardInterrupt:\n",
        "                print(\"Shutting down...\")\n",
        "                stop_event.set()\n",
        "                break\n",
        "\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "q2bk22GxFzR6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once enough data with diverse depth values has been collected, upload the csv files to the sidebar on this notebook and run the code below to train the random forest model, remeber to change the file names and train both arms using seperate csv files. This means you need to run the following code twice for each csv file for each arm."
      ],
      "metadata": {
        "id": "B8jjw5qjF2eV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import pickle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files\n",
        "\n",
        "# Load CSV\n",
        "csv_filename = \"/content/RF_Data_Arm3_cleaned.csv\"\n",
        "df = pd.read_csv(csv_filename, header=0)\n",
        "df.columns = [\"angle_x\", \"angle_y\", \"pixel_x\", \"pixel_y\", \"depth\", \"pitch\", \"roll\"]\n",
        "\n",
        "# Features and targets\n",
        "y = df[[\"angle_x\", \"angle_y\"]].values\n",
        "x = df[[\"pixel_x\", \"pixel_y\", \"depth\", \"pitch\", \"roll\"]].values\n",
        "\n",
        "# Train/test split\n",
        "X_train, X_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# ========== Decision Tree Regressor ==========\n",
        "# Initialize and train decision tree\n",
        "tree = DecisionTreeRegressor(max_depth=22, random_state=42)\n",
        "tree.fit(X_train, y_train)\n",
        "\n",
        "# Save the decision tree model\n",
        "tree_model_path = \"/content/decision_tree_flat_fine2.pkl\"\n",
        "with open(tree_model_path, 'wb') as f:\n",
        "    pickle.dump(tree, f)\n",
        "\n",
        "print(f\"Decision tree trained and saved to {tree_model_path}\")\n",
        "files.download(tree_model_path)\n",
        "\n",
        "# Predict on validation set\n",
        "val_preds_tree = tree.predict(X_val)\n",
        "\n",
        "# Compute MAE for each angle\n",
        "mae_angle0_tree = mean_absolute_error(y_val[:, 0], val_preds_tree[:, 0])\n",
        "mae_angle1_tree = mean_absolute_error(y_val[:, 1], val_preds_tree[:, 1])\n",
        "avg_mae_tree = (mae_angle0_tree + mae_angle1_tree) / 2\n",
        "\n",
        "print(f\"\\nDecision Tree Validation MAE:\")\n",
        "print(f\"  angle_x: {mae_angle0_tree:.2f} degrees\")\n",
        "print(f\"  angle_y: {mae_angle1_tree:.2f} degrees\")\n",
        "print(f\"  Average MAE: {avg_mae_tree:.2f} degrees\")\n",
        "\n",
        "# ====== Compare Predictions to Actuals ======\n",
        "print(\"\\nSample Predictions vs Actual Values for Decision Tree:\")\n",
        "for i in range(10):\n",
        "    predicted = val_preds_tree[i]\n",
        "    actual = y_val[i]\n",
        "    print(f\"[{i}] Predicted: angle_x = {predicted[0]:.2f}, angle_y = {predicted[1]:.2f}  |  Actual: angle_x = {actual[0]:.2f}, angle_y = {actual[1]:.2f}\")\n",
        "\n",
        "\n",
        "# ========== Random Forest Regressor ==========\n",
        "# Initialize and train Random Forest\n",
        "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "# Save the Random Forest model\n",
        "rf_model_path = \"/content/RF_Metal_Arm3.pkl\"\n",
        "with open(rf_model_path, 'wb') as f:\n",
        "    pickle.dump(rf, f)\n",
        "\n",
        "print(f\"Random Forest trained and saved to {rf_model_path}\")\n",
        "files.download(rf_model_path)\n",
        "\n",
        "# Predict on validation set for Random Forest\n",
        "val_preds_rf = rf.predict(X_val)\n",
        "\n",
        "# Compute MAE for Random Forest\n",
        "mae_angle0_rf = mean_absolute_error(y_val[:, 0], val_preds_rf[:, 0])\n",
        "mae_angle1_rf = mean_absolute_error(y_val[:, 1], val_preds_rf[:, 1])\n",
        "avg_mae_rf = (mae_angle0_rf + mae_angle1_rf) / 2\n",
        "\n",
        "print(f\"\\nRandom Forest Validation MAE:\")\n",
        "print(f\"  angle_x: {mae_angle0_rf:.2f} degrees\")\n",
        "print(f\"  angle_y: {mae_angle1_rf:.2f} degrees\")\n",
        "print(f\"  Average MAE: {avg_mae_rf:.2f} degrees\")\n",
        "\n",
        "# ====== Compare Predictions to Actuals ======\n",
        "print(\"\\nSample Predictions vs Actual Values for Random Forest:\")\n",
        "for i in range(10):\n",
        "    predicted = val_preds_rf[i]\n",
        "    actual = y_val[i]\n",
        "    print(f\"[{i}] Predicted: angle_x = {predicted[0]:.2f}, angle_y = {predicted[1]:.2f}  |  Actual: angle_x = {actual[0]:.2f}, angle_y = {actual[1]:.2f}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "uriUGi1lGPdn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 642
        },
        "outputId": "d38cb955-85cb-446b-e880-5b66f20779db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision tree trained and saved to /content/decision_tree_flat_fine2.pkl\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_3e8c69ce-a5df-477a-88b1-d537eb0fe86e\", \"decision_tree_flat_fine2.pkl\", 685162)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Decision Tree Validation MAE:\n",
            "  angle_x: 1.21 degrees\n",
            "  angle_y: 0.23 degrees\n",
            "  Average MAE: 0.72 degrees\n",
            "\n",
            "Sample Predictions vs Actual Values for Decision Tree:\n",
            "[0] Predicted: angle_x = 228.00, angle_y = 200.00  |  Actual: angle_x = 227.50, angle_y = 200.00\n",
            "[1] Predicted: angle_x = 217.00, angle_y = 195.50  |  Actual: angle_x = 221.00, angle_y = 196.00\n",
            "[2] Predicted: angle_x = 224.50, angle_y = 195.00  |  Actual: angle_x = 221.50, angle_y = 195.50\n",
            "[3] Predicted: angle_x = 205.50, angle_y = 207.50  |  Actual: angle_x = 204.50, angle_y = 207.50\n",
            "[4] Predicted: angle_x = 205.50, angle_y = 176.00  |  Actual: angle_x = 205.00, angle_y = 176.00\n",
            "[5] Predicted: angle_x = 219.50, angle_y = 202.00  |  Actual: angle_x = 220.00, angle_y = 202.00\n",
            "[6] Predicted: angle_x = 209.50, angle_y = 206.50  |  Actual: angle_x = 210.00, angle_y = 207.50\n",
            "[7] Predicted: angle_x = 207.00, angle_y = 209.00  |  Actual: angle_x = 204.00, angle_y = 209.50\n",
            "[8] Predicted: angle_x = 219.50, angle_y = 200.50  |  Actual: angle_x = 219.00, angle_y = 199.50\n",
            "[9] Predicted: angle_x = 210.50, angle_y = 186.50  |  Actual: angle_x = 213.50, angle_y = 187.00\n",
            "Random Forest trained and saved to /content/RF_Metal_Arm3.pkl\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_1791be01-6b20-48c0-b30f-031793ae06a1\", \"RF_Metal_Arm3.pkl\", 43264532)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Random Forest Validation MAE:\n",
            "  angle_x: 1.13 degrees\n",
            "  angle_y: 0.15 degrees\n",
            "  Average MAE: 0.64 degrees\n",
            "\n",
            "Sample Predictions vs Actual Values for Random Forest:\n",
            "[0] Predicted: angle_x = 226.71, angle_y = 200.01  |  Actual: angle_x = 227.50, angle_y = 200.00\n",
            "[1] Predicted: angle_x = 219.45, angle_y = 196.03  |  Actual: angle_x = 221.00, angle_y = 196.00\n",
            "[2] Predicted: angle_x = 223.37, angle_y = 195.54  |  Actual: angle_x = 221.50, angle_y = 195.50\n",
            "[3] Predicted: angle_x = 205.19, angle_y = 207.53  |  Actual: angle_x = 204.50, angle_y = 207.50\n",
            "[4] Predicted: angle_x = 204.59, angle_y = 175.78  |  Actual: angle_x = 205.00, angle_y = 176.00\n",
            "[5] Predicted: angle_x = 218.87, angle_y = 201.83  |  Actual: angle_x = 220.00, angle_y = 202.00\n",
            "[6] Predicted: angle_x = 211.33, angle_y = 207.59  |  Actual: angle_x = 210.00, angle_y = 207.50\n",
            "[7] Predicted: angle_x = 206.26, angle_y = 209.40  |  Actual: angle_x = 204.00, angle_y = 209.50\n",
            "[8] Predicted: angle_x = 220.16, angle_y = 199.31  |  Actual: angle_x = 219.00, angle_y = 199.50\n",
            "[9] Predicted: angle_x = 211.84, angle_y = 187.12  |  Actual: angle_x = 213.50, angle_y = 187.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once the .pkl random forest files have been trained, upload them to the Jetson ON."
      ],
      "metadata": {
        "id": "-l4sAq0nu9DG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If there are NaN values in the csv files you can run the following code to clean it up:"
      ],
      "metadata": {
        "id": "S0Bh_GadUE0g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Path to your original CSV file\n",
        "input_csv = \"/content/RF_Data_Arm3.csv\"\n",
        "\n",
        "# Output path for cleaned CSV\n",
        "output_csv = \"/content/RF_Data_Arm3_cleaned.csv\"\n",
        "\n",
        "# Load the CSV file (no header)\n",
        "df = pd.read_csv(input_csv, header=None)\n",
        "\n",
        "# Set column names\n",
        "df.columns = [\"angle_x\", \"angle_y\", \"pixel_x\", \"pixel_y\", \"depth\", \"pitch\", \"roll\"]\n",
        "\n",
        "# Drop rows with NaNs in input or target columns\n",
        "df_cleaned = df.dropna(subset=[\"angle_x\", \"angle_y\", \"pixel_x\", \"pixel_y\", \"depth\", \"pitch\", \"roll\"])\n",
        "\n",
        "# Save the cleaned DataFrame to a new CSV\n",
        "df_cleaned.to_csv(output_csv, index=False, header=False)\n",
        "\n",
        "print(f\"Cleaned dataset saved to: {output_csv}\")\n",
        "print(f\"Original rows: {len(df)}, Cleaned rows: {len(df_cleaned)}\")"
      ],
      "metadata": {
        "id": "hJaYMFhgUNQ8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5aedc022-5a58-4934-c580-967258ab847a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned dataset saved to: /content/RF_Data_Arm3_cleaned.csv\n",
            "Original rows: 5348, Cleaned rows: 5346\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Step 5: Aiming While in Motion"
      ],
      "metadata": {
        "id": "PhLW9lIPGZAy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The ZED X Mini is very low latency, so for aiming in motion a simple Kalman filter is highly effective."
      ],
      "metadata": {
        "id": "UYY0DDsHGhZ0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Step 6: Main code"
      ],
      "metadata": {
        "id": "z1qBndkzIRWN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Main script will be run in a Ros2 workspace, differ to the Ros2_WS folder for more information:"
      ],
      "metadata": {
        "id": "u-tqOfpEIU7h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To increase the inference speed of the Yolo11n ultralytics model run the following two lines on the Jetson ON:"
      ],
      "metadata": {
        "id": "YFV7GoThlkq1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sudo nvpmodel -m 0"
      ],
      "metadata": {
        "id": "hiLTERkUluKc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sudo jetson_clocks"
      ],
      "metadata": {
        "id": "MxUgTm6glwq4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}